---
title: "How Black and White is Language Processing?"
subtitle: "An Investigation into the Noisy-channel Processing of Binomials"
editor: visual

author:
    - name: "ZACHARY NICHOLAS HOUGHTON"
      orcid: "0000-0002-0320-8881"
      degree: "Psychology"
      affiliations:
        - name: "University of California, Davis"
          department: "Department of Psychology"

degree: "Psychology"
dissertation_name: "Dissertation Name"
author_name: "ZACHARY NICHOLAS HOUGHTON"
field_of_study: "Psychology"
committee_member_1: "Dr. Fernanda Ferreira, Chair"
committee_member_2: "Dr. Emily Morgan"
committee_member_3: "Dr. John Henderson"
submission_year: "2025"
  
format:
  pdf:
    template-partials:
      - before-body.tex
      #- toc.tex
    number-sections: true
    latex-engine: xelatex 
    documentclass: scrartcl   # LaTeX document class for professional formatting
    number-depth: 3
    # Caption Formatting
    fig-cap-location: top      # Figure captions above
    tbl-cap-location: top      # Table captions above
    fig-pos: 'htbp'        # Let LaTeX decide where to place the figures
    fig-align: center       # Centering figures
    keep-tex: true             # Optional: for debugging TeX
    latex-output: houghton_thesis.tex
    # Font Settings
    fontsize: 12pt
    mainfont: "Crimson"        # Primary text font
    CJKmainfont: "Noto Serif KR"  # Font for Korean text
    link-citations: true       # Enable hyperlinked citations
    colorlinks: false          # Disable colored hyperlinks
    toc: true
    toc-depth: 3
    #toc-title: "Table of Contents"
    #lot: true                  # Enable List of Tables
    #lof: true                  # Enable List of Figures

    # Page Layout #Not supposed to use geometry for koma apparently
    geometry:
      - left=1in
      - right=1in
      - top=1in
      - bottom=1in

    include-in-header: 
      - include-in-header.tex

  docx:
    number-sections: true
    number-depth: 3
    toc-title: Table of Contents
    toc: true
    toc-depth: 3
    reference-doc: reference.docx
        
      
csl: apa.csl
bibliography: references.bib
---

```{r include = F}
library(tidyverse)
library(knitr)
library(kableExtra)
library(brms)
library(sjPlot)
library(ggpubr)

audio_acc_70 = brm(residual_rts ~ 0 + Intercept + prime_freq * target_freq + 
            (prime_freq * target_freq | Item) + (prime_freq * target_freq | participant),
          data = audio_acc_greater_70,
          iter = 30000, 
          warmup = 15000,
          chains = 4,
          core = 4,
          thin = 4,
          prior = c(set_prior("student_t(3, 0, 30)", class = "b"),
                set_prior("student_t(3, 0, 30)", class = "sd")),
         control = list(adapt_delta = 0.99),
         file = '../Scripts/audio_accuracy_greater_70_exp3' #accuracy_greater_90
)


percent_greater_zero = data.frame(fixef(audio_acc_70, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


audio_acc_70_freq = brm(residual_rts ~ 0 + Intercept + prime_freq * target_freq + 
            (prime_freq * target_freq | Item) + (prime_freq * target_freq | participant),
          data = audio_acc_greater_70_freq,
          iter = 30000, 
          warmup = 15000,
          chains = 4,
          core = 4,
          thin = 4,
          prior = c(set_prior("student_t(3, 0, 30)", class = "b"),
                set_prior("student_t(3, 0, 30)", class = "sd")),
         control = list(adapt_delta = 0.99),
         file = '../Scripts/audio_accuracy_greater_70_freq_exp3' #accuracy_greater_90
)

percent_greater_zero_frequent = data.frame(fixef(audio_acc_70_freq, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)
```

\newpage

\doublespacing

\setlength{\parindent}{4em}

# Abstract {#sec-abstract .unnumbered}

Abstract

\newpage

\pagenumbering{arabic}

# Introduction

Humans have a great deal of flexibility when it comes to linearizing our abstract thoughts into discrete words. For example, to express uncertainty, I have a variety of options ranging from familiar expressions such as *I don't know*, to more novel expressions, such as *to me, it is uncertain*. In other words, when speaking we are faced with the decision of either accessing a holistically stored expression or generating a novel expression by combining words using knowledge of the grammar.

Traditionally, the assumption about this trade off between item-specific and generative knowledge was thought to be a function of a word or phrase's semantic compositionally [i.e., the degree to which the phrase's meaning could be derived from the individual words or morphemes that comprise it; @chomskyAspectsTheorySyntax1965; @pinkerFutureTense2002]. For example, according to generativist theories, regular multi-morphemic words can be composed using rules of the language. As such, a word like *cats* would be generated by accessing the holistically stored word, *cat*, and then generating *cats* by using knowledge of the grammar with respect to plural formation. Similarly, multi-word phrases, such as *I don't know* would be generated by accessing each of the individual words in the phrase and then combining them.

These theories gained a great deal of traction, partially due to concerns about memory limitations. However, more recently we have learned that the brain has a much larger memory capacity than we once thought. For example, @wangDiscoveringCapacityHuman2003 demonstrated that the human brain can store an upwards of 10^8432^ bits. Further, @mollicaHumansStoreMegabytes2019 estimated that the upper bound of memory that it would require to store linguistic knowledge is ten million bits of information, which is well within the estimated amount of storage that the human brain has.

As knowledge of the memory capacity of the brain increased, alternative accounts to holistic storage started gaining traction. These theories grew largely out of the phonetics and categorization literature where generativists' cookie-cutter approach to language was easily shown to fall short. For example, @bybeeWordFrequencyContext2002 demonstrated that the phonetic reduction of a sound advances more greatly in high-frequency words than low-frequency words. If words are the combination of abstract phonemes, then the reduction of a phoneme should proliferate across every word that contains the phoneme. In other words, it's hard to account for the context-specificity of phoneme realizations without a storage mechanism that contains context-specific phonetic detail.

Similarly, @mcmurrayGradientSensitivityWithincategory2008 in their seminal paper demonstrated that people are sensitive to gradient changes of within-category voice onset timing (VOT). VOT is a measure of when the vocal chords begin flapping. While VOT is a continuous measure, it is used by English listeners to determine whether a sound is voiced or unvoiced. Following this, if phonemes are represented as abstract categories (e.g., just *p* or *b*), then VOT should only influence listener's perception if the change in VOT results in a change in the phoneme. That is, if two sounds vary in VOT but are still classified as *p*, participants should not be sensitive to this (if they're decomposing the word into abstract phoneme units). However, @mcmurrayGradientSensitivityWithincategory2008 demonstrated that listeners *are* sensitive to within-category VOT. Specifically, they presented participants with words such as *barricade/parakeet*, where the initial sounds were either voiced or voiceless stops. They then systematically manipulated the VOT for the initial stop and measured the proportion of participants' fixations to the competitor. They found that within-category variability of VOT affected participants' proportion of fixations to the competitor, suggesting sensitivity to within-category variability in VOT.

These findings also sparked similar questions in the word-processing literature. For example, @bybeeEffectUsageDegrees1999 examined the phonetic reduction of *don't* in various contexts. They found that *don't* is more greatly reduced in *I don't know* than in lower-frequency phrases such as *I don't go*. In other words, the phonetic reduction of *I don't know* cannot be attributed to the phonetic reduction of any of the individual parts in isolation. This suggests that *I don't know* has a representation separate from the individual parts. @bybeeEffectUsageDegrees1999 showed similar results for other high-frequency phrases as well, such as *have to*, *want to*, etc. Similarly, @yiEumunHyeonsanggwaBindo2002 demonstrated that tensification in certain multi-word phrases in Korean is also context-specific. Specifically, in Korean certain consonants become tense when they occur after the future tense marker. @yiEumunHyeonsanggwaBindo2002 demonstrated that this tensification is more frequent in high-frequency phrases.

In the Psycholinguistics literature, there has been a rich literature examining the multi-word holistic storage of binomials [@siyanova-chanturiaSeeingPhraseTime2011; @morganAbstractKnowledgeDirect2016; @morganFormalizingConstructionGrammar; @morganFrequencydependentRegularizationIterated2016a; @morganModelingIdiosyncraticPreferences2015; @morganProductiveKnowledgeItemspecific2024; @houghton2024frequencydependentpreferenceextremity; @houghton2023doespredictabilitydrive]. For example, @siyanova-chanturiaSeeingPhraseTime2011 demonstrated that binomials are read faster in their frequent order (e.g., *bread and butter*) than in their infrequent ordering (e.g., *butter and bread*). If binomials were represented and processed word-by-word then it is unclear how to account for this result since the individual words are identical. One possibility is that humans have abstract preferences for ordering words in phrases (e.g., a preference for short words first). @morganAbstractKnowledgeDirect2016 examined this possibility by creating a corpus of binomials and annotating them for semantic and phonological constraints known to influence binomial orderings [@benorChickenEggProbabilistic2006]. They then created a logistic model to combine these constraints into a single generative preference value that indicated the direction and magnitude of the preference. For example, a large generative preference value indicates a strong preference for the alphabetical ordering.

They further examined whether human ordering preferences are driven by these generative preferences for binomials ranging in overall frequency (where overall frequency is the total number of times a binomial occurs in either ordering, e.g., the number of times *bread and butter* occurs plus the number of times *butter and bread* occurs). They found that for low-frequency binomials, human ordering preferences are driven primarily by generative preferences, however for high-frequency binomials human ordering preferences are driven primarily by relative frequency (i.e., the proportion of counts in the alphabetical ordering to the nonalphabetical ordering, e.g., the proportion of counts of *bread and butter* to counts of *butter and bread*). Their results suggest that humans generate low-frequency binomials using generative knowledge of the language, however for high-frequency binomials humans store and access a holistic representation of the entire binomial.

## Frequency-dependent Preference Extremity

Holistic storage also makes rich predictions about language change that have been born out in the literature. For example, there is evidence that ordering preferences become more extreme for high-frequency items relative to low-frequency items [@morganFrequencydependentRegularizationIterated2016a; @liuFrequencydependentRegularizationConstituent2020; @liuFrequencyDependentRegularizationSyntactic2021]. If phrases are generated compositionally without any holistic storage, it is hard to see how high-frequency phrases would become more polarized, especially binomials since both orderings contain the same words. However, this is precisely what the literature has demonstrated. For example, @morganModelingIdiosyncraticPreferences2015 demonstrated that the ordering preferences of binomials are more extreme for high-frequency binomials relative to low-frequency binomials.

Additionally, @liuFrequencydependentRegularizationConstituent2020 demonstrated that the dative alternation (e.g., *give him the ball* vs *give the ball to him*) also shows evidence of frequency-dependent preference extremity. Specifically, they found that for high-frequency verbs, there is a stronger preference for using one dative alternation over the other than for low-frequency verbs. Similarly, @liuFrequencyDependentRegularizationSyntactic2021 examined the ordering of adjectives in adjective-adjective-noun (AAN) phrases (e.g., *dark blue sky*). They found that AAN phrases with higher overall frequency (where overall frequency is the sum of counts in either ordering) show more polarized ordering preferences.

While holistic storage is a prerequisite for frequency-dependent preference extremity, it isn't enough by itself to account for this phenomenon. In addition to holistic storage, it is possible that frequency-dependent preference extremity arises as an interaction between imperfect learning and transmission across generations [@morganFrequencydependentRegularizationIterated2016a; @houghton2024frequencydependentpreferenceextremity]. This idea was proposed by @morganFrequencydependentRegularizationIterated2016a who demonstrated that a frequency-independent regularization bias can account for frequency-dependent preference extremity arising across generations of learners.

Specifically they used a 2-alternative iterated learning paradigm [@realiEvolutionFrequencyDistributions2009] to simulate the evolution of binomial ordering preferences across generations of speakers. In their model, a speaker first produces N binomial expressions in either ordering in proportion to their learned preferences. For the first generation of speakers, this proportion is simply the generative preference of the binomial. The learner then "hears" these Nbinomial expressions and updates their hypothesis about the proportion that each ordering of that binomial occurs in. This data generation process alone simply results in learner's converging on the prior [@griffithsLanguageEvolutionIterated2007]. Thus, @morganFrequencydependentRegularizationIterated2016a introduced a frequency-independent regularization bias into their model. This was a prior that the learner had to overcome. Thus, if there was enough evidence, learners would develop stronger preferences for the ordering of a binomial, however, if there was not strong evidence then the learner's preferences would be overpowered by the prior. This model resulted in frequency-dependent preference extremity arising across generations of learners.

However, while their results demonstrate that a frequency-independent regularization bias can account for frequency-dependent preference extremity, it's unclear what process this bias is analogous to in language.

## Noisy-channel Processing

One possibility is that the the frequency-independent regularization bias is a function of noisy-channel processing.[^1]

[^1]: It is worth mentioning here that in parallel to the development of noisy-channel processing theories, other accounts making similar claims also emerged [e.g., @ferreiraGoodEnoughApproach2007]. Many of these theories accept that language processing must allow for flexibility and it's often difficult to disentangle them. While we take a noisy-channel approach in the present thesis, all of the claims we make are also compatible with good-enough processing theories as well, and we leave the task of disentangling the two to future work.

When processing language, we are faced with a great deal of noise in our environment. This can be literal noise in our environment, such as the sound of a loud city, or noise introduced by the communication device, such as static in a cellphone conversation. It can also be errors made by the speaker (saying the wrong thing) or by the listener (hearing the wrong thing). Despite this, human's language processing system appears to be quite robust to noise. One possible explanation is that people may be tracking, not simply what the speaker is saying, but what probable utterances the speaker *could* say [@gibsonNoisyChannelAccountCrosslinguistic2013; @levyNoisychannelModelHuman2008].

There is a great deal of evidence that people do take noise into account. First and most obviously, when a listener misses a word due to simply not hearing it, it very rarely causes a complete breakdown in communication. Further, @ganongPhoneticCategorizationAuditory1980 demonstrated that people process a non-word as being a word under noisy conditions. Similarly, @feltyMisperceptionsSpokenWords found that when listeners misperceive a word, the word that they believed to have heard is a higher frequency than the word spoken. These results suggest that in noise listeners are relying on information about the language, such as what utterances are more probable.

Interestingly, people will sometimes even hear a grammatical sentence and interpret the meaning differently from what they have heard due to noisy-channel processing. For example @christiansonThematicRolesAssigned2001 found that when people read the sentence *While the man hunted the deer ran into the woods*, people will answer in the affirmative for the question *Did the man hunt the deer?* as well as the question *Did the deer run into the woods?*. @levyNoisychannelModelHuman2008 argued that since both interpretations can arise from a single insertion, noisy-channel processing offers an explanation for this finding.

Following this, @gibsonNoisyChannelAccountCrosslinguistic2013 formalized noisy-channel processing using a Bayesian framework. They modeled noisy-channel processing as a process wherein the listener estimates the probability of the speaker's intended utterance ($s_i$) given what they perceived ($s_p$, @eq-gibsonnoisy) Specifically, the listener is modeled as a rational Bayesian who estimates the probability of the speaker's intended utterance given the perceived utterance as being proportional to the probability of the intended utterance in general times the probability of that perceived utterance given the intended utterance. This is formalized mathematically in @eq-gibsonnoisy [reproduced from @gibsonNoisyChannelAccountCrosslinguistic2013] where $s_i$ is the speaker's intended sentence and $s_p$ is the perceived sentence. The prior ($P(s_p|s_i)$) is the likelihood of the $s_i$ being corrupted to $s_p$.

$$
P(s_i|s_p)\propto P(s_i) P(s_p|s_i) 
$$ {#eq-gibsonnoisy}

The model in @gibsonNoisyChannelAccountCrosslinguistic2013 made several predictions. Specifically, their model predicted that comprehenders should be more likely to interpret a semantically implausible sentence (e.g., *the mother gave the candle the daughter*) as being plausible (e.g., *the mother gave the candle to the daughter*) if there is increased noise (which they accomplished by adding syntactic errors to the filler items). Their model also predicted that increasing the probability of an implausible utterance (e.g., by adding more implausible items to the fillers) should lead to an increased rate of implausible interpretations. They tested these predictions by giving participants a series of sentences, some of which were semantically implausible but had semantically plausible alternatives that participants could interpret the sentence as being. These alternatives varied in how different they were from the perceived utterances. Some of them varied from the perceived utterance by a single insertion or a single deletion, while others varied by two insertions or two deletions. By manipulating the number of semantically implausible sentences as well as the number of filler items with syntactic errors, both of the predictions that their model made were born out.

Given these results, @houghton2024frequencydependentpreferenceextremity extended @morganFrequencydependentRegularizationIterated2016a's model. Specifically, we used a 2-alternative iterated learning paradigm, learners heard N tokens of a given binomial in either alphabetical or nonalphabetical order and learns a preference. The learner's goal was to learn the ordering preferences for each binomial. Then after learning the ordering preferences, they then produced N tokens to the next generation. This process then repeats.

Specifically, after hearing a binomial, the learner in our model updated their beliefs in proportion to what they believed the speaker's intended ordering was, which was modeled with pseudo counts. For example, if they believed the intended utterance was A and B with 60% probability and B and A with 40% probability, then they would add 0.6 and 0.4 to the pseudo counts for A and B and B and A respectively.[^2] These updated beliefs would result in the learner prescribing an even higher probability of A and B occurring.

[^2]: See @houghton2024frequencydependentpreferenceextremity for a more detailed explanation of our computational model.

Without a regularization bias, this model would simply result in convergence to the prior [@griffithsLanguageEvolutionIterated2007]. Thus, our model also contained a noisy-channel processing component. After hearing a binomial, the learner in our model would interpret the opposite ordering occasionally (following @eq-gibsonnoisy). That is, if the learner hears B and A, but is confident that the intended ordering was actually A and B, they will update their beliefs as if they had heard A and B.

To help build intuition for this: suppose a learner believes there is a 60% chance that the speaker intended to say A and B, but they heard B and A. Without a noisy-channel processing component, the learner would update their belief, down-weighting the probability of A and B and up-weighting the probability of B and A. However, with noisy-channel processing, the learner may actually assume the speaker intended to say A and B (after calculating this probability according to @eq-gibsonnoisy). This would then result in updating their beliefs as if they had heard A and B. For high-frequency binomials, the learner may be quite confident about their expectations for the ordering of the binomial, and may be more willing to interpret B and A as A and B. However, for low-frequency binomials, the learner may be less confident and restrain from interpreting B and A as A and B.

Indeed, this is precisely the result we found in @houghton2024frequencydependentpreferenceextremity. That is, that for low-frequency binomials, the learner's belief about the intended ordering was not particularly strong and was pulled towards the prior. However, for high-frequency binomials, as the learning continued iteratively across generations, frequency-dependent preference extremity arose.

Our results in @houghton2024frequencydependentpreferenceextremity demonstrated that a noisy-channel processing model in an iterative learning paradigm can predict frequency-dependent preference extremity. It also makes a crucial prediction: that learners sometimes hear *B and A*, but actually interpret it to be *B and A*. In the present study we explore this prediction.

## Present Thesis

@houghton2024frequencydependentpreferenceextremity's model predicts that learners sometimes hear one binomial ordering but interpret it to be the opposite ordering. If this is the case, then it is possible that upon hearing, e.g., *white and black*, the listener actually processes it as *black and white*. There is a great deal of evidence that activating a phrase results in decreased processing time if encountering the same phrase shortly after [e.g., @tabossi1980linguisticcontextpriming]. If this is the case, then hearing *white and black* should actually speed up the processing of *black and white* more than it speeds up the processing of *white and black*. This is the prediction that we set out to test in the present study. By using a primed self-paced reading task with a mental rotation task, we examine whether *white and black* primes *black and white* more than it primes *white and black*.

# Methods

## Procedure

In order to examine the effects of noisy-channel processing on the reading times of binomials, we used a primed self-paced reading task with a mental rotation task. Specifically, participants were first presented auditorily with a prime sentence while simultaneously completing a mental rotation task. The mental rotation task involved determining whether one was a simple rotation or a mirror image of another image. The rotation was always either 0 degrees or 45 degrees. Participants were tasked with either pressing the 'f' key or the 'j' key (counter balanced between participants) to indicate that the image was either a simple rotation or a mirror image. The idea behind the mental rotation task was that by forcing participants to multi-task they may rely more on noisy-channel processing than when they can focus solely on the prime sentences.

After listening to the prime sentence and completing the mental rotation, participants then completed a self-paced reading task. Specifically, participants were presented with a sentence word-by-word and pressed the 'space' key when they were ready to proceed to the next word. Reaction times for the time it took participants to press the 'space' key were recorded for each word. After each sentence, participants were presented with a comprehension question to test their attention. The comprehension questions were questions either about the prime sentence or the sentence they had just read.

## Stimuli

Our stimuli consisted of 30 polarized binomials.[^3] Specifically, these were binomials that occurred more than 400,000 times (out of 323,592,921,465 tokens), calculated using the Google *n*-grams corpus [@michel2011quantitativeanalysisculture]. Additionally, they all had a relative frequency of either less than -0.30 and greater than 0.30. Relative frequency indicates which ordering is more preferred (and to what magnitude). For example, a binomial that occurs equally as many times in both orders would have a relative frequency of zero (where relative frequency ranges from -0.50 to 0.50). A relative frequency value below 0 indicates that the nonalphabetical ordering occurred more than the alphabetical ordering in corpus data, and a number above zero indicates the opposite. The magnitude of the number indicates the strength, with 0.50 indicating that the binomial occurred exclusively in alphabetical ordering and -0.50 indicated the binomial occurred exclusively in nonalphabetical ordering.

[^3]: Our stimuli and analyses are available at the following link: <https://github.com/znhoughton/Noisy-Channel-Binomial-Preferences>. The stimuli are also included in the appendix section (@sec-full-list-of-stimuli).

For each of these binomials, we created a prime and a target sentence containing the binomial in either order. Specifically, for each binomial, three prime sentences were made: one that contained the binomial in the frequent ordering (e.g., *bread and butter*), one that contained the infrequent ordering, (*butter and bread*), and one that did not contain a binomial at all. These priming conditions are referred to as the frequent, infrequent, and unrelated primes respectively. We also made two target sentences (the sentences read during the self-paced reading task) for each binomial. The target sentences contained the binomial in either the frequent or infrequent ordering. Finally, we also included 30 filler trials, which did not contain binomials in the prime or target sentences.

Our prime and target sentences were crossed such that each target occurred with each prime, however no participant was presented with the same binomial in more than one trial.

## Participants

228 University of California, Davis undergraduate students were given course credit to participate in the study. We also recruited an additional 220 participants through Prolific. Altogether, 448 people participated in our study.

Participants were randomly presented with one of 6 conditions. Since our design is a 3 x 2 design, 6 conditions were created so that participants did not encounter the same binomial in more than one trial.

## Analysis

We divided the sentences into a target and spillover region to be our region of analysis. This region included the 3 words in the binomial along with the 3 following words. We then excluded participants whose reading times on this region were less than 100ms or greater than 5000 ms [following @morganAbstractKnowledgeDirect2016]. We also excluded participants who had an average accuracy below 0.7 on the audio comprehension questions (the questions that asked about the auditorily presented prime). Finally, we excluded trials for which the residual reading times were outside of 2.5 standard deviations from the mean.

We then ran two Bayesian mixed-effects regression models with residual reading times as the dependent variable.[^4]

[^4]: A pre-registration of our study is available at the following link: <https://aspredicted.org/t324-swgk.pdf>.

For the first model, we were interested in whether a frequent prime affected the residual reading times. As such, we filtered the dataframe to include trials that contained either an unrelated or frequent prime. We then treatment coded our variables such that for the prime sentences, 0 indicated an unrelated prime and 1 indicated a frequent prime. For target sentences, 0 indicated an infrequent target while 1 indicated a frequent target. We then ran a model with residual reading time as the dependent variable, fixed-effects for prime, target, and their interaction, as well as maximal random-effects [following @barrRandomEffectsStructure2013].

Our second model was similar, however we were interested in how the infrequent prime affected residual reading times. As such, we filtered our dataframe to include trials that contained either the unrelated or infrequent prime. We then treatment coded our variables such that 0 indicated an unrelated prime and 1 indicated an infrequent prime.

Our model syntax was the same for both models, as mentioned previously the difference was the levels of the variables included in the data.

$$
\begin{aligned}
\text{Residual Reading Time} & \sim \text{Intercept} + \text{prime freq} * \text{target freq} \\ 
&+ (\text{prime freq} * \text{target freq} | \text{Item}) + (\text{prime freq} * \text{target freq} | \text{participant})
\end{aligned}
$$ {#eq-models}

# Results

We first examined whether a frequent prime facilitated the reading of the frequent ordering of the binomial more than the reading time of the infrequent ordering. Following @houghtonTaskdependentConsequencesDisfluency2024, in addition to reporting the estimates we also report the percentage of posterior samples greater than zero. Bayesian statistics don't force us into a binary interpretation of significance or non-significance, by reporting the percentage of posterior samples greater than zero we are able to interpret the results in a more nuanced manner.

The results are presented in @tbl-frequentresults and visualized in @fig-fullresults. Since prime and target types were treatment coded, the Intercept represents the estimated reading times for unrelated prime sentences with an infrequent target sentence. Coefficient estimates represent the distance from the Intercept. Although the credible interval crosses zero, over 93% of the posterior samples for the effect of frequent prime were greater than zero, suggesting that for not-frequent targets, the frequent prime resulted in slower reading times than the unrelated prime. Similarly, over 93% of the posterior samples for frequent target were less than zero, suggesting that for unrelated primes, the frequent target was read faster. Finally, about 90% of the samples for the interaction effect were less than zero, suggesting that the difference between the reading times in the unrelated prime condition and the reading times in the frequent prime condition were larger for infrequent targets than frequent targets. In other words, the frequent prime speeds up the reading times for the frequent ordering of the binomial more than the infrequent ordering of the binomial.

```{r, echo = F, message = F}
#| label: tbl-frequentresults
#| tbl-cap: 'Results of the statistical model for the frequent vs unrelated prime.'


m_frequent = as.data.frame(fixef(audio_acc_70_freq)) %>%
  mutate(term = c('Intercept', 'Frequent Prime', 'Frequent Target', 'Frequent Prime:Frequent Target'))

percent_greater_zero_frequent = percent_greater_zero_frequent %>%
  arrange(match(beta_coefficient, c('Intercept', 'prime_freqfrequent', 'target_freqfrequent', 'prime_freqfrequent.target_freqfrequent')))

m_frequent = m_frequent %>%
  mutate(percent_greater_zero = percent_greater_zero_frequent$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


m_frequent = m_frequent %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

m_frequent %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '14em')

```

Next we examined whether the infrequent prime speeds up the infrequent ordering of the binomial more than the frequent ordering. If readers are engaged in noisy-channel processing when listening to the prime, they may actually activate *bread and butter* when they hear *butter and bread*. This would result in the infrequent prime speeding up the *frequent* ordering of the binomial more than the infrequent ordering.

The results are presented in @tbl-infrequentresults and visualized in @fig-fullresults. Similar to the previous model, since prime and target types were treatment coded, the Intercept represents the estimated reading times for unrelated prime sentences with an infrequent target sentence. Coefficient estimates represent the distance from the Intercept. We find no meaningful main-effect for infrequent primes or frequent targets, but we do find a meaningful interaction effect. While the credible interval crosses zero, over 90% of the posterior samples were greater than zero. The results suggest that the infrequent prime speeds up reading for the infrequent target more than the frequent target.

```{r, echo = F, message = F}
#| label: tbl-infrequentresults
#| tbl-cap: 'Results of the statistical model for the infrequent vs unrelated prime.'


m_infrequent = as.data.frame(fixef(audio_acc_70)) %>%
  mutate(term = c('Intercept', 'Infrequent Prime', 'Frequent Target', 'Infrequent Prime:Frequent Target'))

percent_greater_zero = percent_greater_zero %>%
  arrange(match(beta_coefficient, c('Intercept', 'prime_freqnotMfrequent', 'target_freqfrequent', 'prime_freqnotMfrequent.target_freqfrequent')))

m_infrequent = m_infrequent %>%
  mutate(percent_greater_zero = percent_greater_zero$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


m_infrequent = m_infrequent %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

m_infrequent %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '14em')

```

```{r, echo = F, out.width = '80%', fig.align = 'center', warning = F, message = F}
#| label: fig-fullresults
#| fig-cap: "Plot of our results. Points indicate"
#| fig-height: 5
#| fig-width: 8


p1 = plot(conditional_effects(audio_acc_70_freq), plot = F)[[3]] +
  scale_color_manual(
    values = c("not-frequent" = "#66c2a5", "frequent" = "#8da0cb"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  scale_fill_manual(
    values = c("not-frequent" = "#66c2a5", "frequent" = "#8da0cb"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  labs(
    x = 'Prime Sentence',
    y = 'Residual Reading Times',
    color = 'Target Sentence',
    fill = 'Target Sentence'
  ) +
  scale_x_discrete(
    labels = c('unrelated' = 'Unrelated', 'frequent' = 'Frequent')
  ) +
  theme_bw() +
  theme(
    axis.title = element_text(size = 16),         # Axis labels
    axis.text = element_text(size = 14),          # Axis tick labels
    legend.title = element_text(size = 14),       # Legend title
    legend.text = element_text(size = 12)         # Legend items
  )

p2 = plot(conditional_effects(audio_acc_70), plot = F)[[3]] +
  scale_color_manual(
    values = c("not-frequent" = "#66c2a5", "frequent" = "#8da0cb"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  scale_fill_manual(
    values = c("not-frequent" = "#66c2a5", "frequent" = "#8da0cb"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  labs(
    x = 'Prime Sentence',
    y = 'Residual Reading Times',
    color = 'Target Sentence',
    fill = 'Target Sentence'
  ) +
  scale_x_discrete(
    labels = c('unrelated' = 'Unrelated', 'not-frequent' = 'Infrequent')
  ) +
  theme_bw() +
  theme(
    axis.title = element_text(size = 16),         # Axis labels
    axis.text = element_text(size = 14),          # Axis tick labels
    legend.title = element_text(size = 14),       # Legend title
    legend.text = element_text(size = 12)         # Legend items
  )

ggarrange(p1, p2, common.legend = T)

```

# Discussion

Our results demonstrate that both the frequent and infrequent ordering of a given binomial speeds up the reading times of the respective ordering. That is, priming the frequent ordering speeds up the reading of the frequent ordering, and priming the infrequent ordering speeds up the reading of the infrequent ordering.

-Not noisy-channel processing?

-maybe accessibility?

-Still lots of evidence of noisy-channel processing, how to explain?

\clearpage

# References {.unnumbered}

::: {#refs}
:::

\newpage

# Appendix {.unnumbered}

\appendix

\renewcommand{\thesection}{\Alph{section}}

\setcounter{section}{0}

\counterwithin{figure}{section}

\counterwithin{table}{section}

# Full List of Stimuli {#sec-full-list-of-stimuli .appendix}

Our full stimuli list is included below.

::: landscape
```{r, echo = F, message = F}
#| label: tbl-appendixstimuli
#| tbl-cap: 'Full set of stimuli.'

stimuli = read_csv('../Data/key.csv') %>%
  filter(PrimeType != 'filler') %>%
  select(Binomial, RelFreq,  GenPref, PrimeType, SentenceType, Sentence, Prime) 
  
stimuli %>%
  kable(
    row.names = FALSE,
    booktabs = TRUE,
    format = "latex",
    escape = TRUE,
    longtable = TRUE
  ) %>%
  kable_styling(
    latex_options = c("striped", "hold_position"),
    font_size = 6,
    full_width = FALSE
  ) %>%
  row_spec(0, bold = TRUE)



```
:::

