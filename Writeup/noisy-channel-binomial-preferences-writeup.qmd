---
title: "The Bolts and Nuts of Language Processing:"
subtitle: "An Investigation into the Noisy-channel Processing of Binomials"
editor: visual

author:
    - name: "ZACHARY NICHOLAS HOUGHTON"
      orcid: "0000-0002-0320-8881"
      degree: "Psychology"
      affiliations:
        - name: "University of California, Davis"
          department: "Department of Psychology"

degree: "Psychology"
dissertation_name: "Dissertation Name"
author_name: "ZACHARY NICHOLAS HOUGHTON"
field_of_study: "Psychology"
committee_member_1: "Fernanda Ferreira, Chair"
committee_member_2: "Emily Morgan"
committee_member_3: "John Henderson"
submission_year: "2025"
  
format:
  pdf:
    template-partials:
      - before-body.tex
      #- toc.tex
    number-sections: true
    latex-engine: xelatex 
    documentclass: scrartcl   # LaTeX document class for professional formatting
    number-depth: 3
    # Caption Formatting
    fig-cap-location: top      # Figure captions above
    tbl-cap-location: top      # Table captions above
    fig-pos: 'htbp'        # Let LaTeX decide where to place the figures
    fig-align: center       # Centering figures
    keep-tex: true             # Optional: for debugging TeX
    latex-output: houghton_thesis.tex
    # Font Settings
    fontsize: 12pt
    mainfont: "Crimson"        # Primary text font
    CJKmainfont: "Noto Serif KR"  # Font for Korean text
    link-citations: true       # Enable hyperlinked citations
    colorlinks: false          # Disable colored hyperlinks
    toc: true
    toc-depth: 3
    #toc-title: "Table of Contents"
    #lot: true                  # Enable List of Tables
    #lof: true                  # Enable List of Figures

    # Page Layout #Not supposed to use geometry for koma apparently
    geometry:
      - left=1in
      - right=1in
      - top=1in
      - bottom=1in

    include-in-header: 
      - include-in-header.tex

  docx:
    number-sections: true
    number-depth: 3
    toc-title: Table of Contents
    toc: true
    toc-depth: 3
    reference-doc: reference.docx
        
      
csl: apa.csl
bibliography: references.bib
---

```{r include = F}
library(tidyverse)
library(knitr)
library(kableExtra)
library(brms)
library(sjPlot)
library(ggpubr)

key = read_csv('../Data/key.csv')

audio_acc_70 = brm(residual_rts ~ 0 + Intercept + prime_freq * target_freq + 
            (prime_freq * target_freq | Item) + (prime_freq * target_freq | participant),
          data = audio_acc_greater_70,
          iter = 30000, 
          warmup = 15000,
          chains = 4,
          core = 4,
          thin = 4,
          prior = c(set_prior("student_t(3, 0, 30)", class = "b"),
                set_prior("student_t(3, 0, 30)", class = "sd")),
         control = list(adapt_delta = 0.99),
         file = '../Scripts/audio_accuracy_greater_70_exp3' #accuracy_greater_90
)


percent_greater_zero = data.frame(fixef(audio_acc_70, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


audio_acc_70_freq = brm(residual_rts ~ 0 + Intercept + prime_freq * target_freq + 
            (prime_freq * target_freq | Item) + (prime_freq * target_freq | participant),
          data = audio_acc_greater_70_freq,
          iter = 30000, 
          warmup = 15000,
          chains = 4,
          core = 4,
          thin = 4,
          prior = c(set_prior("student_t(3, 0, 30)", class = "b"),
                set_prior("student_t(3, 0, 30)", class = "sd")),
         control = list(adapt_delta = 0.99),
         file = '../Scripts/audio_accuracy_greater_70_freq_exp3' #accuracy_greater_90
)

percent_greater_zero_frequent = data.frame(fixef(audio_acc_70_freq, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


corpus = read_csv("../Data/corpus.csv") %>%
  mutate('FrequencyPer350Mil' = OverallFreq / 323592921465 * 350000000) %>% #Frequency per 350 million, per that Levy paper
  mutate(FrequencyPer350Mil = as.integer(FrequencyPer350Mil))


simulations_of_corpus = read_csv('../Data/corpus_sim_results.csv')

plot_data = simulations_of_corpus 

our_model_p1 = ggplot(data = plot_data, aes(x = posterior_mu, y = ..density..)) +
  geom_histogram(color = 'black', fill = 'white') +
  #geom_density() +
  #facet_grid(generation ~ Overall.Frequency) +
  xlab('Proportion of occurrences in alpahbetical order')+
  ylab('Density') +
  theme(plot.margin = unit(c(0.5,1,0.5,1), 'cm')) +
  scale_y_continuous(breaks = c(0, 0.5, 1, 1.5, 2), limits = c(0, 2)) +
  theme_bw() +
  theme(axis.title = element_text(size = 8)) #

corpus_p1 = ggplot(data = corpus, aes(x = RelFreq, y = ..density..)) +
  geom_histogram(color = 'black', fill = 'white') +
  #geom_density() +
  xlab('Proportion of occurrences in alpahbetical order') +
  ylab('Density') +
  theme(plot.margin = unit(c(0.5,1,0.5,1), 'cm')) +
  scale_y_continuous(breaks = c(0, 0.5, 1, 1.5, 2, 2.5, 3), limits = c(0, 3)) +
  theme_bw() +
  theme(axis.title = element_text(size = 8))

corpus_p2 = ggplot(data = corpus, aes(x = GenPref, y = ..density..)) +
  geom_histogram(color = 'black', fill = 'white') +
  #geom_density() +
  xlab('Generative ordering preferences') +
  ylab('Density') +
  theme(plot.margin = unit(c(0.5,1,0.5,1), 'cm')) +
  scale_y_continuous(breaks = c(0, 0.5, 1, 1.5, 2, 2.5, 3), limits = c(0, 3)) +
  scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1.0), limits = c(0, 1)) +
  theme_bw() +
  theme(axis.title = element_text(size = 8))


new_df2 = read_csv('../Data/full_graph_smallerN.csv')

plot_data2 = new_df2
```

\newpage

\doublespacing

\setlength{\parindent}{4em}

# Abstract {#sec-abstract .unnumbered}

There is often more than one way to convey the same meaning. For example, one might go to the store to buy a *radio and television*, or one might just as easily go to the store to buy a *television and radio*. Recent studies have shown that for high-frequency binomials, speakers develop a strong preference for one binomial ordering (e.g., *bread and butter*) over the alternative (e.g., *butter and bread*). This polarization of preferences for high-frequency items is called frequency-dependent preference extremity. How does this preference emerge over time? One possibility is that it is a consequence of noisy-channel processing. That is, for high-frequency items, it is possible that when a listener hears *butter and bread*, they assume that the speaker actually intended to say *bread and butter*. In order to test this, we examined whether hearing *butter and bread* actually primes *bread and butter* more than it does *butter and bread*. However, we find that both the frequent and infrequent orderings of binomials prime the exact ordering they were heard in, suggesting that noisy-channel processing may not be the processing mechanism behind frequency-dependent preference extremity.

\newpage

\pagenumbering{arabic}

# Introduction

Humans have a great deal of flexibility when it comes to linearizing our abstract thoughts into discrete words or phrases. For example, to express uncertainty, we have a variety of options ranging from familiar expressions such as *I don't know*, to more novel expressions, such as *to me, it is unknown*. In other words, when speaking we are faced with the decision of either accessing a holistically stored expression or generating a novel expression by combining words using knowledge of the grammar.

Traditionally, the assumption with respect to this trade off between item-specific and generative knowledge was that it is a function of a word or phrase's semantic compositionality [i.e.\, the degree to which the phrase's meaning could be derived from the individual words or morphemes that comprise it\; @chomskyAspectsTheorySyntax1965; @pinkerFutureTense2002]. For example, according to generativist theories, regular multi-morphemic words can be composed using rules of the language. As such, the word *cats* would be generated by accessing the holistically stored word, *cat*, and then generating *cats* by using knowledge of the grammar. Similarly, multi-word phrases, such as *I don't know* would be generated by accessing each of the individual words in the phrase, *I*, *don't*, and *know*, and then combining them.

Additionally, some formal syntacticians have also argued that even in cases where a multi-word phrase (e.g., an idiom) is stored holistically, the phrase is still licensed by the grammar [e.g., @culicover2017multiwordconstructionsgrammar]. For example, @culicover2017multiwordconstructionsgrammar demonstrated that multi-word phrases often following the rules of the grammar. They argued that since the verb in the phrase *kicked the bucket* can still be inflected as in *she may kick the bucket soon*, that even in cases where a multi-word phrase is stored holistically, it is stored with its phrase structure rules.

Generativist theories gained a great deal of traction, partially due to concerns about memory limitations. However, more recently we have learned that the brain has a much larger memory capacity than we once thought. For example, @wangDiscoveringCapacityHuman2003 demonstrated that the human brain can store an upwards of 10^8432^ bits. Further, @mollicaHumansStoreMegabytes2019 estimated that the upper bound of memory that it would require to store linguistic knowledge is ten million bits of information, which is well within the estimated amount of storage that the human brain has.

As knowledge of the memory capacity of the brain increased, alternative accounts of storage began gaining traction. These theories grew largely out of the phonetics literature where generativists' approach to language fell short. For example, @bybeeWordFrequencyContext2002 demonstrated that the phonetic reduction of a sound advances more quickly in high-frequency words than low-frequency words. If words are a combination of abstract phonemes, then the reduction of a phoneme should proliferate across every word that contains the phoneme. In other words, it's hard to account for the context-specificity of phoneme realizations without a storage mechanism that contains context-specific phonetic detail.

Similarly, in their seminal paper @mcmurrayGradientSensitivityWithincategory2008 demonstrated that people are sensitive to gradient changes of within-category voice onset timing (VOT). VOT is a measure of when the vocal chords begin flapping with respect to the production of a phoneme. While VOT is a continuous measure, it is used by English listeners to make a binary decision as to whether a sound is voiced or voiceless. Following this, if phonemes are represented as abstract categories (e.g., just *p* or *b*), then VOT should only influence listener's perception if the change in VOT results in a change in the phoneme. If two sounds vary in VOT but are still classified as *p*, participants should not be sensitive to the difference in VOT (if they're decomposing the word into abstract phonemes).

@mcmurrayGradientSensitivityWithincategory2008 demonstrated that listeners *are* sensitive to within-category VOT. Specifically, they presented participants with words such as *barricade/parakeet*, where the initial sounds were either voiced or voiceless stops. They then systematically manipulated the VOT for the initial stop and measured the proportion of participants' fixations to the competitor. They found that within-category variability of VOT affected the proportion of fixations to the competitor, suggesting sensitivity to within-category variability in VOT. It is difficult to account for this sensitivity if words are composed via abstract representations of sounds (i.e., phonemes). As such, this finding has been taken as strong evidence that people are storing exemplars of sounds when they experience them as opposed to simply storing abstract representations. While this is a phenomenon at the individual sound-level, the connection to multi-word storage may be clear by now: if people are storing individual sounds instead of simply storing phoneme-level abstractions, then the same may be true on the multi-word phrase level: people may store phrases holistically instead of generating them through abstract representations of the individual words.

As such, the evidence for item-specific representations of sounds naturally sparked similar theoretical debates about the representations of multi-word phrases. For example, @bybeeEffectUsageDegrees1999 examined the phonetic reduction of *don't* in various contexts. They found that *don't* is more greatly reduced in *I don't know* than in lower-frequency phrases such as *I don't go*. In other words, the phonetic reduction of *I don't know* cannot be attributed to the phonetic reduction of any of the individual parts in isolation. This suggests that *I don't know* has a representation separate from the individual parts.[^1] @bybeeEffectUsageDegrees1999 showed similar results for other high-frequency phrases as well, such as *have to*, *want to*, etc. Similarly, @yiEumunHyeonsanggwaBindo2002 demonstrated that tensification in certain multi-word phrases in Korean is also context-specific. Specifically, in Korean certain consonants become tense when they occur after the future tense marker. @yiEumunHyeonsanggwaBindo2002 demonstrated that this tensification is more frequent in high-frequency phrases. The context-specificity of the phonetic reduction of multi-word phrases is strong evidence for the holistic storage of multi-word phrases.

[^1]: One could account for this by positing adjacency effects such as co-articulation, which definitely are responsible to a certain extent for phonetic reduction. However, this seems unlikely to explain all of the effects seen in @bybeePhonologyLanguageUse2003 since even in the phrase *I don't know, don't* seems to only be reducible in specific contexts. For example, in sentences that contain an additional clause (e.g., in a sentence containing a complementizer phrase, such as *I don't know what you're talking about*, *I don't know* cannot be reduced as much as it can be when it's produced alone (e.g., as a response to a simple question) where it can be reduced to only a nasally vowel with intonation.

In the Psycholinguistics literature, there has been a rich literature examining the multi-word holistic storage of binomials [@siyanova-chanturiaSeeingPhraseTime2011; @morganAbstractKnowledgeDirect2016; @morganFormalizingConstructionGrammar; @morganFrequencydependentRegularizationIterated2016a; @morganModelingIdiosyncraticPreferences2015; @morganProductiveKnowledgeItemspecific2024; @houghton2024frequencydependentpreferenceextremity; @houghton2023doespredictabilitydrive]. For example, @siyanova-chanturiaSeeingPhraseTime2011 demonstrated that binomials are read faster in their frequent order (e.g., *bread and butter*) than in their infrequent ordering (e.g., *butter and bread*). At a first glance, if binomials are represented and processed word-by-word (i.e., if binomials are not holistically stored) then it may seem difficult to account for the results of @siyanova-chanturiaSeeingPhraseTime2011 since the individual words are identical across different orderings of the same binomial (i.e., the words in *cats and dogs* are the same as in *dogs and cats*).[^2] However, one possible account for the asymmetrical ordering preferences is that humans learn abstract preferences for the ordering of words in phrases (e.g., a preference for short words first). @morganAbstractKnowledgeDirect2016 examined this possibility by creating a corpus of binomials and annotating them for semantic and phonological constraints known to influence binomial orderings [@benorChickenEggProbabilistic2006]. They then created a logistic model to combine these constraints into a single generative preference value that indicated the direction and magnitude of the preference.

[^2]: Although see @frazier2000processingcoordinatestructures for an argument that posits coordinate structures as asymmetrical adjunction structures headed by the first conjunct, which may also account for the different ordering effects seen in @siyanova-chanturiaSeeingPhraseTime2011.

@morganAbstractKnowledgeDirect2016 then examined whether human ordering preferences are driven by these abstract preferences for binomials ranging from low to high overall frequency (where overall frequency is the total number of times a binomial occurs in either ordering, e.g., the number of times *bread and butter* occurs plus the number of times *butter and bread* occurs). Specifically, they used a self-paced reading task where participants read binomials in sentence contexts. They found that for low-frequency binomials, human reading times were driven primarily by generative preferences, however for high-frequency binomials human reading times were driven primarily by relative frequency (i.e., the proportion of counts in the alphabetical ordering to the nonalphabetical ordering). Their results suggest that humans compose low-frequency binomials using abstract knowledge of the language, however for high-frequency binomials humans store and access a holistic representation of the entire binomial.

## Frequency-dependent Preference Extremity

Holistic storage also makes rich predictions about language change that have been borne out in the literature. For example, there is evidence for a phenomenon called **frequency-dependent preference extremity**, wherein ordering preferences become more extreme for high-frequency items relative to low-frequency items [@morganAbstractKnowledgeDirect2016; @liuFrequencydependentRegularizationConstituent2020; @liuFrequencyDependentRegularizationSyntactic2021]. A great deal of evidence for this phenomenon comes from the literature on binomial ordering preferences, where it has been demonstrated that humans develop strong ordering preferences for high-frequency binomials but not low-frequency binomials [e.g.\, a strong preference for *bread and butter* over *butter and bread*\, but not a strong preference for *radio and television* over *television and radio*\; @morganAbstractKnowledgeDirect2016; @morganFrequencydependentRegularizationIterated2016a; @morganModelingIdiosyncraticPreferences2015].

Evidence of frequency-dependent preference extremity is not limited to binomials either. @liuFrequencydependentRegularizationConstituent2020 demonstrated that the dative alternation (e.g., *give him the ball* vs *give the ball to him*) also shows evidence of frequency-dependent preference extremity. Specifically, they found that for high-frequency verbs, there is a stronger preference for using one dative alternation structure over the other than for low-frequency verbs. Similarly, @liuFrequencyDependentRegularizationSyntactic2021 examined the ordering of adjectives in adjective-adjective-noun (AAN) phrases (e.g., *dark blue sky*). They found that AAN phrases with higher overall frequency (where overall frequency is the sum of counts in either adjective ordering; e.g., count of *big blue sky* plus *blue big sky*.) show more polarized ordering preferences.

One way to account for frequency-dependent preference extremity is with holistic storage. For example, as mentioned earlier there is evidence that humans rely on abstract preferences for low-frequency binomials but rely on their experience with a binomial for high-frequency binomials. This might help to explain why people develop strong preferences for high-frequency binomials but not low-frequency binomials. However, while holistic storage may be a driving factor for frequency-dependent preference extremity, it isn't enough by itself to account for this phenomenon. That is, high-frequency binomials being stored holistically does not necessarily lead to them being used more.

In addition to holistic storage, it is possible that frequency-dependent preference extremity arises as an interaction between imperfect learning and transmission across generations [@morganFrequencydependentRegularizationIterated2016a; @houghton2024frequencydependentpreferenceextremity]. For example, @morganFrequencydependentRegularizationIterated2016a argued that humans have a bias to regularize[^3] (i.e., a bias for one form to become preferred over competing alternatives) productions to decrease variability [@hudsonkam2005regularizingunpredictablevariation]. It is possible that this regularization bias causes high-frequency binomials to become more polarized (i.e., more regularized). Indeed, they found that a computational model that contains a frequency-independent regularization bias does result in frequency-dependent preference extremity. They demonstrated that this is because in their model, learners rely on their prior knowledge (abstract preferences in this case) when there isn't enough data (such as in the case of lower frequency binomials), but when they have enough data they overcome their prior knowledge resulting in more regularized/polarized productions.

[^3]: Following @morganFrequencydependentRegularizationIterated2016a, we define *regularization* as a reduction in variability/entropy of a distribution.

Specifically @morganFrequencydependentRegularizationIterated2016a used a 2-alternative iterated learning paradigm [@realiEvolutionFrequencyDistributions2009] to simulate the evolution of binomial ordering preferences across generations of speakers. In their model, a learner first hears N binomial expressions. The learner's goal is to learn the underlying distribution that generated the binomials. For example, if a speaker produces *bread and butter* with 0.9 probability and *butter and bread* with 0.1 probability, the goal of the learner is to learn these probabilities. After learning these preferences, the learner then produces N binomial expressions for the next generation of learners. This continues iteratively for N generations of learners.

Typically, learners in a 2-alternative iterated learning paradigm are modeled as rational Bayesian learners using Bayes' rule. For example, in a classical 2-alternative iterated learning paradigm, the learner estimates the probability of the binomial being ordered alphabetically (alphabetical ordering is used as a relatively neutral reference order). Specifically, the learner estimates this by multiplying the probability of observing the alphabetical ordering of a given binomial under a given hypothesis about the ordering preferences (the likelihood, $P(x_1|\theta_1)$) by the prior probability of that hypothesis (prior, $P(\theta_1)$).

In other words, the likelihood is equivalent to the probability of a sequence of binomials containing $x_1$ binomials in alphabetical ordering generated by a speaker that produces the alphabetical ordering with some probability $\theta_1$. The prior is the probability distribution over the values of $\theta_1$, which describe the learner's prior beliefs about the probability of each ordering. @eq-likelihoodbernoulli and @eq-priorbeta provide the mathematical formalization of the likelihood and prior[^4] respectively in the 2-alternative iterated learning paradigm [@realiEvolutionFrequencyDistributions2009].

[^4]: Note that $\alpha$ is specified a-priori and determines the shape of the beta distribution. Further, since the Bernoulli likelihood and the Beta prior form a conjugate pair, the resulting posterior is technically also a Beta distribution; @realiEvolutionFrequencyDistributions2009.

$$
P(x_1|\theta_1)= {N \choose x_1}\theta^{x_1}_1(1-\theta_1)^{N-x_1}
$$ {#eq-likelihoodbernoulli}

$$
P(\theta_1) = Beta(\frac{\alpha}{2},\frac{\alpha}{2})
$$ {#eq-priorbeta}

However, @morganFrequencydependentRegularizationIterated2016a demonstrated that this approach does not capture the effects of frequency-dependent preference extremity. As such, they modified the prior such that there was a regularization parameter. Specifically, they used the regularized incomplete beta function, which includes a regularization parameter. This parameter is set to the same value for all binomials (and as such is frequency independent). However, they demonstrated that by adding a regularization parameter, the model predicts frequency-dependent preference extremity. This parameter pressures productions to be more regular (regardless of the frequency of the binomial). Thus, if there is not strong evidence for a preference for one ordering over the other, the learner's preferences are pulled towards the prior. If there is enough evidence, however, they learn a preference and this preference becomes more polarized over time. As such, this model was able to predict frequency-dependent preference extremity arising across generations of learners.

A visualization of their results is shown in @fig-morganfreqresults. The results demonstrate that as R increases (i.e., as the regularization parameter increases), more binomials become polarized (as demonstrated by greater probability density around values of 0 and 1). While their results demonstrate that a frequency-independent regularization bias can account for frequency-dependent preference extremity, it's unclear what process this bias is analogous to in language learning/processing.

```{r echo = F, fig.align = 'center', warning = F, message = F, out.width = '100%'}
#| label: fig-morganfreqresults
#| fig-cap: "Visualization of results reproduced from @morganFrequencydependentRegularizationIterated2016a. R indicates the regularization bias, $\\nu$ indicates strength of the prior. The x-axis indicates the predicted ordering preference, with zero being a strong preference for the nonalphabetical ordering and 1 being a strong preference for the alphabetical ordering. Y-axis is the probability density. The results demonstrate that their model predicts polarized preferences for some binomials (i.e., increase in probability density for predicted ordering preferences near 0 and 1)."
#| fig-align: center
knitr::include_graphics("Figures/morgan_freq_dep_reg_results.pdf")



```

## Noisy-channel Processing

One possibility is that the frequency-independent regularization bias is a consequence of noisy-channel processing.[^5]

[^5]: It is worth mentioning here that in parallel to the development of noisy-channel processing theories, other accounts making similar claims also emerged [e.g., @ferreiraGoodEnoughApproach2007]. Many of these theories accept that language processing must allow for flexibility and it's often difficult to disentangle them. While we take a noisy-channel approach in the present thesis, all of the claims we make are also compatible with good-enough processing theories as well, and we leave the task of disentangling the two theories to future work.

When processing language, we are faced with a great deal of noise in our environment. This can be literal noise in our environment, such as the sound of a loud city, or noise introduced by a communication device, such as static in a cellphone conversation. It can also be errors made by the speaker (speech errors) or by the listener (perceptual errors). Despite the abundance of noise in both our environment and in the input, the language processing system appears to be quite robust to noise. One possible explanation is that people may be tracking, not simply what they are hearing, but also what they think the speaker actually intended to say [@gibsonNoisyChannelAccountCrosslinguistic2013; @levyNoisychannelModelHuman2008]. Thus in some cases where people hear something implausible, they may actually think that the speaker intended to say something else, and process it as if they did say the intended utterance.

There is a great deal of evidence that people do take noise into account. First and most obviously, when a listener misses a word due to simply not hearing it (e.g., a loud noise interrupted the utterance), it very rarely causes a complete breakdown in communication. Further, @ganongPhoneticCategorizationAuditory1980 demonstrated that people process a non-word as being a word under noisy conditions. Similarly, @feltyMisperceptionsSpokenWords found that when listeners misperceive a word, the word that they believed to have heard is a higher frequency than the word spoken. These results suggest that in noise listeners are relying on information about the language, such as what utterances are more probable, to overcome the perceptual difficulties.

Interestingly, people will sometimes even hear a grammatical sentence and interpret the meaning differently from what they have heard due to noisy-channel processing. For example @christiansonThematicRolesAssigned2001 found that when people read the sentence *While the man hunted the deer ran into the woods*, people will answer in the affirmative for the question *Did the man hunt the deer?* as well as the question *Did the deer run into the woods?*. People interpret this sentence as having been *While the man hunted the deer, it ran into the woods.* @levyNoisychannelModelHuman2008 argued that since both interpretations can arise from a single insertion, noisy-channel processing offers an explanation for this finding.

Following this, @gibsonNoisyChannelAccountCrosslinguistic2013 formalized a noisy-channel processing model using a Bayesian framework. They modeled noisy-channel processing as a process wherein the listener estimates the probability of the speaker's intended utterance ($s_i$) given what they perceived ($s_p$, @eq-gibsonnoisy) Specifically, the listener is modeled as a rational Bayesian who estimates the probability of the speaker's intended utterance given the perceived utterance as being proportional to the probability of the intended utterance in general times the probability of that perceived utterance given the intended utterance. This is formalized mathematically in [@eq-gibsonnoisy; reproduced from @gibsonNoisyChannelAccountCrosslinguistic2013] where $s_i$ is the speaker's intended sentence and $s_p$ is the perceived sentence. The prior ($P(s_p|s_i)$) is the probability of the intended sentence ($s_i$) being corrupted to the perceived sentence ($s_p$).

$$
P(s_i|s_p)\propto P(s_i) P(s_p|s_i) 
$$ {#eq-gibsonnoisy}

The model in @gibsonNoisyChannelAccountCrosslinguistic2013 makes several predictions. For one, their model predicts that comprehenders should be more likely to interpret a semantically implausible sentence (e.g., *the mother gave the candle the daughter*) as being plausible (e.g., *the mother gave the candle to the daughter*) if there is increased noise because an increase in noise results in a greater probability that a plausible sentence was corrupted by noise (i.e., an increase in noise results in an increase in the value of $P(s_p=\text{implausible}|s_i=\text{plausible})$). Their model also predicts that increasing the probability of an implausible utterance should lead to an increased rate of implausible interpretations because by increasing the probability of an implausible utterance, the probability that the speaker intended to say an implausible utterance also increases (i.e., an increasing in the value of $P(s_i=\text{implausible})$).

@gibsonNoisyChannelAccountCrosslinguistic2013 tested these predictions by giving participants a series of sentences, some of which were semantically implausible but had semantically plausible alternatives that participants could interpret the sentence as being. These alternatives varied in how different they were from the perceived utterances. Some of them varied from the perceived utterance by a single insertion or a single deletion, while others varied by two insertions or two deletions. In order to test their first prediction, they increased the noise by manipulating the number of filler items with syntactic errors. They found that their model's first prediction was borne out: participants were more likely to interpret the semantically implausible sentence as being plausible. In order to test their second prediction, they also manipulated the probability of an implausible utterance by increasing the number of implausible sentences in the filler items. They found that their model's second prediction was also borne out: participants were more likely to interpret the implausible sentences as being implausible.

Given these results, @houghton2024frequencydependentpreferenceextremity extended @morganFrequencydependentRegularizationIterated2016a's model to examine whether a noisy-channel processing model integrated with an iterated learning model can account for frequency-dependent preference extremity. Specifically, we used a 2-alternative iterated learning paradigm. In this paradigm, learners are modeled as having heard N tokens of a given binomial in either alphabetical or nonalphabetical order while updating their hypothesis about the inferred probability of each ordering of the binomial. In our model, the learner's goal was to learn the ordering preferences for each binomial. After learning the ordering preferences for each binomial, the learner then produced N tokens to the next generation. This process then repeated iteratively.

After hearing a binomial, the learner in our model updated their beliefs in proportion to how probable they believed the speaker's intended ordering was (calculated using @eq-gibsonnoisy), which was modeled with pseudo counts. For example, if they believed the intended utterance was *A and B* with 60% probability and *B and A* with 40% probability, then they would add 0.6 and 0.4 to the pseudo counts for *A and B* and *B and A* respectively.[^6]

[^6]: See @houghton2024frequencydependentpreferenceextremity for a more detailed explanation of our computational model.

To help build intuition for this: suppose a learner believes there is a 60% chance that the speaker intended to say *A and B*, but they heard *B and A*. Without a noisy-channel processing component, the learner would update their belief, down-weighting the probability of *A and B* and up-weighting the probability of *B and A* (because they heard *B and A*). However, in our model, the learner may actually assume the speaker intended to say *A and B* (after calculating this probability according to @eq-gibsonnoisy), but had actually misspoken and said *B and A*. This would then result in updating their beliefs as if they had heard *A and B* (or more accurately, in proportion to the learner's belief about the probability that the speaker intended *A and B*). For high-frequency binomials, the learner encounters the binomial more and has more opportunities to update their ordering preferences, which may result in that binomial developing polarized preferences. However, for low-frequency binomials, the learner does not encounter the binomial as many times and has fewer opportunities to update their beliefs, resulting in less polarized preferences.

In @houghton2024frequencydependentpreferenceextremity, we tested whether this model can account for frequency-dependent preference extremity and found that it can. Specifically, we found that for low-frequency binomials, the learner's belief about the intended ordering was not particularly strong. However, for high-frequency binomials, as the language was transmitted across generations, high-frequency binomials developed polarized preferences (i.e., frequency-dependent preference extremity).

Our results in @houghton2024frequencydependentpreferenceextremity are illustrated in @fig-corpusourmodel. The plot demonstrates that as the overall frequency of the binomial increases (N), the inferred binomial ordering preferences become more polarized (i.e., closer to zero or one). This plot demonstrates that the model in @houghton2024frequencydependentpreferenceextremity is able to capture the effects of frequency-dependent preference extremity.

Altogether, the results in @houghton2024frequencydependentpreferenceextremity suggested that a noisy-channel processing model integrated with an iterative learning paradigm may account for the emergence of frequency-dependent preference extremity (though only when the listener infers more noise than the speaker is actually producing). The model also makes a crucial prediction: that learners sometimes hear *B and A*, but actually interpret it to be *A and B*. In the present study we explore this prediction.

```{r echo = F, out.width = '80%', fig.align = 'center', warning = F, message = F}
#| fig-cap: "A plot of the ordering preferences predicted by the model in @houghton2024frequencydependentpreferenceextremity. The values at the top indicate the frequency of the binomial (N). The y-axis indicates the probability density and the x-axis indicates the ordering preference. Thus values closer to 0 and 1 are more extreme ordering preferences. The plot demonstrates that as the frequency of the binomial increases, the predicted ordering preferences become more extreme. This pattern is also observed in the corpus data in @morganModelingIdiosyncraticPreferences2015."
#| label: fig-corpusourmodel

plot_data2 = new_df2 %>% 
  mutate(p_noise = round(p_noise, 3), prior_prob_noise = round(prior_prob_noise, 3)) %>%
  filter(p_noise == 0.067 & prior_prob_noise == 0.033)

full_plot = ggplot(plot_data2, aes(x = posterior_mu, y = ..density..)) +
  geom_histogram(color = 'black', fill = 'white') +
  facet_wrap(~Overall.Frequency) + #speaker noise and N on x-axis, listener noise on y-axis
  ylab('Density') +
  xlab(bquote(P(S[i]))) +
  scale_x_continuous(breaks = c(0, 0.5, 1), labels = c('0', '0.5', '1')) +
  theme_bw() +
  theme(strip.text = element_text(
    size = 11, color = "black"),
        axis.title = element_text(size = 13))

full_plot

```

## Present Thesis

The model in @houghton2024frequencydependentpreferenceextremity predicts that learners sometimes hear one binomial ordering but interpret it to be the opposite ordering. If this is the case, then it is possible that upon hearing, e.g., *white and black*, the listener actually processes it as *black and white*. There is a great deal of evidence that activating a phrase results in decreased processing time if encountering the same phrase shortly after [e.g., repetition priming effects\; @tabossi1980linguisticcontextpriming]. If this is the case, then hearing *white and black* should actually speed up the processing of *black and white* more than it speeds up the processing of *white and black*. This is the prediction that we set out to test in the present study.

# Methods

## Procedure

In order to examine the effects of noisy-channel processing on the reading times of binomials, we used a primed self-paced reading task with a mental rotation task. Specifically, participants were first presented auditorily with a prime sentence while simultaneously completing a mental rotation task. The mental rotation task involved determining whether one image was a simple rotation or a mirror image of another image (We used images of the capital letter 'F'). The rotation was always either 0 degrees or 45 degrees. Participants were tasked with either pressing the 'f' key or the 'j' key to indicate that the image was either a simple rotation or a mirror image. The experiment was counterbalanced between experiments with respect to whether participants pressed 'f' to indicate that the image was a mirror image, or whether they pressed j' to. The reasoning behind the mental rotation task was to that forcing participants to complete an additional task while listening to the prime sentence may encourage them to rely more on noisy-channel processing than if they could focus solely on the prime sentences. More specifically, completing two tasks simultaneously leads to less attention being allocated to the signal, which may encourage listeners to rely more on noisy-channel processing.

On each trial, after listening to the prime sentence and simultaneously completing the mental rotation, participants then completed a self-paced reading task. Specifically, participants were presented with a sentence word-by-word. After reading the word, they then pressed the 'space' key to proceed to the next word. Reaction times for the time it took participants to press the 'space' key were recorded for each word. After each sentence, participants were presented with a comprehension question to test their attention. The comprehension questions were questions either about the prime sentence or the sentence they had just read.

## Stimuli

Our stimuli consisted of 30 polarized binomials.[^7] Specifically, these were binomials that occurred more than 400,000 times (out of 323,592,921,465 tokens), calculated using the Google *n*-grams corpus [@michel2011quantitativeanalysisculture]. Additionally, all of our items had a relative frequency of either less than -0.30 and greater than 0.30. Relative frequency indicates which ordering is more preferred (and to what magnitude). For example, a binomial that occurs equally as many times in both orders would have a relative frequency of zero (where relative frequency ranges from -0.50 to 0.50). A relative frequency value below 0 indicates that the nonalphabetical ordering occurred more than the alphabetical ordering in corpus data, and a number above zero indicates the opposite. The magnitude of the number indicates the strength, with 0.50 indicating that the binomial occurred exclusively in alphabetical ordering and -0.50 indicated the binomial occurred exclusively in nonalphabetical ordering. Thus binomials with a relative frequency below -0.3 and above 0.3 are quite polarized in their ordering.

[^7]: Our stimuli and analyses are available at the following link: <https://github.com/znhoughton/Noisy-Channel-Binomial-Preferences>. The stimuli are also included in the appendix section (@sec-full-list-of-stimuli).

For each of these binomials, we created a prime and a target sentence containing the binomial in either order. Specifically, for each binomial, one sentence was created that contained the binomial in either the frequent or infrequent order and another unrelated sentence that did not contain any binomial was made as a control. These priming conditions are referred to as the frequent, infrequent, and unrelated prime conditions respectively. We also made a target sentence (the sentences read during the self-paced reading task) that contained the binomial in either the frequent or infrequent ordering. A table demonstrating our six conditions is presented in @tbl-conditionslist. Finally, we also included 30 filler trials, which did not contain binomials in the prime or target sentences.

```{r echo = F}
#| label: tbl-conditionslist
#| tbl-cap: "A table of our conditions."

example_sentence = key %>% 
  filter(Item == 21) %>%
  mutate(target_word = rep(c('gentlemen and ladies', 'ladies and gentlemen'), times = 3),
         prime_word = rep(c('gentlemen and ladies', 'ladies and gentlemen', 'Unrelated'), each = 2)) %>%
  select(Condition, target_freq, prime_freq, target_word, prime_word) %>%
  mutate(target_freq = case_when(target_freq == 'not-frequent' ~ 'Infrequent',
                                 target_freq == 'frequent' ~ 'Frequent')) %>%
  mutate(prime_freq = case_when(prime_freq == 'not-frequent' ~ 'Infrequent',
                                prime_freq == 'frequent' ~ 'Frequent',
                                prime_freq == 'unrelated' ~ 'Unrelated'))

colnames(example_sentence) = c('Condition', 'Target Freq.', 'Prime Freq.', 'Target Binomial', 'Prime Binomial')
example_sentence %>%
  select(everything()) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 12, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '5em')
```

Our prime and target sentences were crossed such that each target occurred with each prime, however no participant was presented with the same binomial in more than one trial.

## Participants

228 University of California, Davis undergraduate students were given course credit to participate in the study. We also recruited an additional 220 participants through Prolific. We then excluded participants based on their accuracy on the comprehension questions that asked about the prime sentences. Participants were randomly presented with one of 6 conditions. Since our design is a 3 x 2 design, 6 conditions were created so that participants did not encounter the same binomial in more than one trial.

For both analyses, participants were excluded for having an accuracy below 0.7 on the comprehension questions about the auditorily presented prime. 194 participants were excluded for having an accuracy below our threshold, leaving a total of 254 participants. Although this accuracy cutoff resulted in a large number of participants being excluded, it is likely due to the difficulty of the task. The prime sentence was given to participants auditorily while they completed a mental rotation task. They then read a sentence in a self-paced reading task before answering the question about the prime.

## Analysis

We divided the sentences into a single region which contained the three words of the binomial along with the 3 words following the binomial. We then excluded trials for which the reading times on this region were less than 100ms or greater than 5000ms [following @morganAbstractKnowledgeDirect2016]. We also excluded participants who had an average accuracy below 0.7 on the audio comprehension questions (the questions that asked about the auditorily presented prime).

Next we calculated residual reading times for each item. Residual reading times are a by-participant measure of reading times that take the effect of word length into account. Specifically, they are the residual error of a linear regression model that regresses reading time by word length for each participant [calculated using data from all non-sentence-final words in non-practice trials following @morganAbstractKnowledgeDirect2016]. We then summed the residual reading times for each word in the 6-word region to get a single residual reading time score for each sentence. Finally, we excluded trials for which the residual reading times were outside of 2.5 standard deviations from the mean.

We then ran two Bayesian mixed-effects regression models with residual reading times as the dependent variable.[^8]

[^8]: A pre-registration of our study is available at the following link: <https://aspredicted.org/t324-swgk.pdf>.

For the first model, we were interested in the effect of the frequent prime on the residual reading times of the frequent and infrequent orderings for each binomial. As such, we filtered the dataframe to include trials that contained either an unrelated or frequent prime. We then treatment coded our variables such that for the prime sentences, 0 indicated an unrelated prime and 1 indicated a frequent prime. For target sentences, 0 indicated an infrequent target while 1 indicated a frequent target. We then ran a model with residual reading time as the dependent variable, fixed-effects for prime, target, and their interaction, as well as maximal random-effects [following @barrRandomEffectsStructure2013].

Our second model was similar, however we were interested in the effect of infrequent primes on residual reading times. As such, we filtered our dataframe to include trials that contained either the unrelated or infrequent prime. We then treatment coded our variables such that 0 indicated an unrelated prime and 1 indicated an infrequent prime. Our model syntax was the same for both models, as mentioned previously the difference was the levels of the variables included in the data.

$$
\begin{aligned}
\text{Residual Reading Time} & \sim \text{Intercept} + \text{prime freq} * \text{target freq} \\ 
&+ (\text{prime freq} * \text{target freq} | \text{Item}) + (\text{prime freq} * \text{target freq} | \text{participant})
\end{aligned}
$$ {#eq-models}

# Results

We first examined whether a frequent prime facilitated the reading of the frequent ordering of the binomial more than the reading time of the infrequent ordering. Following @houghtonTaskdependentConsequencesDisfluency2024, in addition to reporting the estimates we also report the percentage of posterior samples greater than zero. Bayesian statistics don't force us into a binary interpretation of significance or non-significance; by reporting the percentage of posterior samples greater than zero we are able to interpret the results in a more nuanced manner.

In both analyses, the mean accuracy on the audio comprehension questions was 85% and the mean accuracy on all comprehension questions was \~96%. Additionally, mean accuracy on the mental rotation task was \~94%. Interestingly, there was no real difference in accuracy scores for mental rotation trials where the angle was 0 degrees (94.7% accuracy) and trials where the angle was 45 degrees (93.6%).[^9]

[^9]: In previous pilot versions of the experiment, we made the mental rotation task harder. However, the increase in difficulty eliminated the priming effect (possibly because participants had to allocate more attentional resources to the rotation task). Therefore we opted for an easier mental rotation task, hence the high accuracy scores.

The results are presented in @tbl-frequentresults and visualized in @fig-fullresults. In our first analysis, since prime and target types were treatment coded, the Intercept represents the estimated reading times for unrelated prime sentences with an infrequent target sentence. Coefficient estimates represent the distance from the Intercept. Although the credible interval crosses zero, over 93% of the posterior samples for the effect of frequent prime were greater than zero, suggesting that for not-frequent targets, the frequent prime resulted in slower reading times than the unrelated prime. Similarly, over 93% of the posterior samples for frequent target were less than zero, suggesting that for unrelated primes, the frequent target was read faster. Finally, about 90% of the samples for the interaction effect were less than zero, suggesting that the difference between the reading times in the unrelated prime condition and the reading times in the frequent prime condition were larger for infrequent targets than frequent targets. In other words, the frequent prime speeds up the reading times for the frequent ordering of the binomial more than it speeds up the infrequent ordering of the binomial.

```{r, echo = F, message = F}
#| label: tbl-frequentresults
#| tbl-cap: 'Results of the statistical model for the frequent vs unrelated prime.'


m_frequent = as.data.frame(fixef(audio_acc_70_freq)) %>%
  mutate(term = c('Intercept', 'Frequent Prime', 'Frequent Target', 'Frequent Prime:Frequent Target'))

percent_greater_zero_frequent = percent_greater_zero_frequent %>%
  arrange(match(beta_coefficient, c('Intercept', 'prime_freqfrequent', 'target_freqfrequent', 'prime_freqfrequent.target_freqfrequent')))

m_frequent = m_frequent %>%
  mutate(percent_greater_zero = percent_greater_zero_frequent$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


m_frequent = m_frequent %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

m_frequent %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 12, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '14em')

```

Next we examined whether the infrequent prime speeds up the reading time of the infrequent ordering of the binomial more than it speeds up the reading time of the frequent ordering. If readers are engaged in noisy-channel processing when listening to the prime, they may actually activate *bread and butter* when they hear *butter and bread*. This would result in the infrequent prime speeding up the *frequent* ordering of the binomial more than the infrequent ordering.

The results are presented in @tbl-infrequentresults and visualized in @fig-fullresults. Similar to the previous model, since prime and target types were treatment coded, the Intercept represents the estimated reading times for unrelated prime sentences with an infrequent target sentence. Coefficient estimates represent the distance from the Intercept. We find no meaningful main-effect for infrequent primes or frequent targets, but we do find a meaningful interaction effect. While the credible interval crosses zero, over 90% of the posterior samples were greater than zero. The results suggest that the infrequent prime speeds up the reading of the infrequent target more than the frequent target.

```{r, echo = F, message = F}
#| label: tbl-infrequentresults
#| tbl-cap: 'Results of the statistical model for the infrequent vs unrelated prime.'


m_infrequent = as.data.frame(fixef(audio_acc_70)) %>%
  mutate(term = c('Intercept', 'Infrequent Prime', 'Frequent Target', 'Infrequent Prime:Frequent Target'))

percent_greater_zero = percent_greater_zero %>%
  arrange(match(beta_coefficient, c('Intercept', 'prime_freqnotMfrequent', 'target_freqfrequent', 'prime_freqnotMfrequent.target_freqfrequent')))

m_infrequent = m_infrequent %>%
  mutate(percent_greater_zero = percent_greater_zero$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


m_infrequent = m_infrequent %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

m_infrequent %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 12, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '14em')

```

```{r, echo = F, out.width = '80%', fig.align = 'center', warning = F, message = F}
#| label: fig-fullresults
#| fig-cap: "Plot of our model estimates. The x-axis represents whether the prime was unrelated, frequent, or infrequent. The y-axis corresponds to the residual reading times. Color indicates whether the target was infrequent (green) or frequent (blue). The left plot compares the unrelated primes to frequent primes, the right plot compares the unrelated primes to infrequent primes. The result suggest that the primed ordering is read faster regardless of whether the primed binomial ordering is frequent or infrequent."
#| fig-height: 7
#| fig-width: 11


p1 = plot(conditional_effects(audio_acc_70_freq), plot = F)[[3]] +
  scale_color_manual(
    values = c("not-frequent" = "#2e6f5f", "frequent" = "#435582"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  scale_fill_manual(
    values = c("not-frequent" = "#2e6f5f", "frequent" = "#435582"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  labs(
    x = 'Prime Sentence',
    y = 'Residual Reading Times',
    color = 'Target Sentence',
    fill = 'Target Sentence'
  ) +
  scale_x_discrete(
    labels = c('unrelated' = 'Unrelated', 'frequent' = 'Frequent')
  ) +
  theme_bw() +
  theme(
    axis.title = element_text(size = 16),         # Axis labels
    axis.text = element_text(size = 14),          # Axis tick labels
    legend.title = element_text(size = 14),       # Legend title
    legend.text = element_text(size = 12)         # Legend items
  ) 

p2 = plot(conditional_effects(audio_acc_70), plot = F)[[3]] +
  scale_color_manual(
    values = c("not-frequent" = "#2e6f5f", "frequent" = "#435582"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  scale_fill_manual(
    values = c("not-frequent" = "#2e6f5f", "frequent" = "#435582"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  labs(
    x = 'Prime Sentence',
    y = 'Residual Reading Times',
    color = 'Target Sentence',
    fill = 'Target Sentence'
  ) +
  scale_x_discrete(
    labels = c('unrelated' = 'Unrelated', 'not-frequent' = 'Infrequent')
  ) +
  theme_bw() +
  theme(
    axis.title = element_text(size = 16),         # Axis labels
    axis.text = element_text(size = 14),          # Axis tick labels
    legend.title = element_text(size = 14),       # Legend title
    legend.text = element_text(size = 12)         # Legend items
  ) 

ggarrange(p1, p2, common.legend = T)

```

# Discussion

<!--# if bread and butter is stored holistically, but butter and bread is generated compositionally, that might also help explain the results -->

Our results demonstrate that both the frequent and infrequent ordering of a given binomial speed up the reading times of the respective ordering. That is, priming the frequent ordering speeds up the reading of the frequent ordering, and priming the infrequent ordering speeds up the reading of the infrequent ordering.

Our model in @houghton2024frequencydependentpreferenceextremity predicted the opposite result, that hearing the infrequent binomial ordering might actually result in learner's accessing the frequent ordering of the binomial. The model makes two assumptions that are crucial to the present study. First, the model assumes that both the frequent and infrequent ordering are stored holistically. That is, it assumes that both *bread and butter* and *butter and bread* are stored holistically. Second, the model assumes that noisy-channel processing can cause the listener to hear one ordering but assume that the speaker's intended utterance was actually the opposite ordering.

With respect to the first assumption, it is certainly possible that both orderings are stored holistically [e.g., @ambridgeStoredAbstractionsRadical2020]. However, it is also possible that only the frequent orderings for polarized binomials are stored holistically. Indeed, a great deal of the evidence for stored items suggests that frequency drives holistic storage [@kapatsinskiFrequencyEmergencePrefabs2009; @bybeeEffectUsageDegrees1999; @bybeePhonologyLanguageUse2003; @morganAbstractKnowledgeDirect2016; @morganFormalizingConstructionGrammar; @morganProductiveKnowledgeItemspecific2024; @arnonMoreWordsFrequency2010]. It is possible that noisy-channel processing interacts with multi-word holistically stored items differently than with multi-word items that aren't stored holistically. For example, there is evidence that holistically stored phrases "fuse" together [@kapatsinskiFrequencyEmergencePrefabs2009]. It is also the case that holistically stored multi-morphemic words are less susceptible to speech errors [@stembergerAreInflectedForms2004]. Given these results, a holistically stored binomial such as *bread and butter* may not be as susceptible to the same substitution errors that would lead to a speaker producing the speech error *butter and bread*. Listeners may be sensitive to this and thus may not believe that it is a probable speech error.

Alternatively, it's possible that the results we see here are independent of the holistic storage of binomials. For example, perhaps noisy-channel processing occurs at a higher-level than priming does, potentially occurring after the acoustics for the binomial have been processed. In this scenario, while the listener may hear *butter and bread* and interpret the sentence as containing the frequent ordering of the binomial, it does not undo the fact that they heard the acoustics of *butter and bread*. Priming may be lower-level and thus simply hearing the acoustics may result in the priming of *butter and bread* more than *bread and butter*. Even after noisy-channel processing activates the alternative lexical representation, it may not feed back down into the phonological activations of the listener, hence the lack of a difference in priming.

<!--# future work with a sentence recall task would be interesting instead of spr -->

<!--# Would also be fun to explore priming in holistically stored items -->

On the other hand, it is also possible people aren't even interpreting *butter and bread* as *bread and butter* in the first place (i.e., it is possible that binomials are not undergoing noisy-channel processing). There are a few possible explanations for why this might be. The first possibility is that hearing polarized binomials in the infrequent ordering is quite surprising. If the listener is expecting *bread and butter*, then hearing *butter and bread* may draw attention to the binomial, and thus the listener may be confident that they did infact hear *butter and bread*. This confidence would prevent the listener from interpreting the binomial as the more frequent ordering, explaining why there is no priming of *bread and butter*.

It's also possible that the size of the units matter. Much of the literature on noisy-channel processing involves short prepositions being inserted or deleted. However in our case, many of the binomials are multi-syllabic. It is possible that listeners are more likely to assume that the speaker forgot to say a preposition, such as *in* or *up*, than to assume that the speaker accidentally swapped two multi-syllabic words (e.g., in the case of *gentlemen and ladies* instead of *ladies and gentlemen*). On the other hand, there is evidence that people do interpret semantically implausible sentences as being semantically plausible even if the semantically plausible interpretation requires positing a substitution [@poppelsStructuresensitiveNoiseInference2016]. Further, word and phrase exchanges are a very common type of speech error [@fromkin1973speech], so a robust system of language processing should be able to account for these types of errors without incurring too much of a cost. However, it is still the case that the prepositions used in @poppelsStructuresensitiveNoiseInference2016 were short prepositions as well. As such, it is possible that the size of the units plays a role in how willing the listener is to assume that the speaker misspoke, or to assume that the listener misheard.

Finally, it's possible that semantic plausibility also plays a large role in noisy-channel processing. That is, both orders of binomials are semantically plausible. It is simply the case that one is more frequent than the other. Further, while some high-frequency binomials have an idiomatic meaning (e.g., *bread and butter* meaning something that is easy/routine for someone), the sentences in the present study encouraged a compositional reading (since the sentences had to be compatible with both orderings of the binomial). It is possible that semantic implausibility is a pre-requisite to noisy-channel processing, even if an utterance is low-frequency. Perhaps in sentences that encourage an idiomatic reading, participants would be more likely to use noisy-channel processing. Even if not a pre-requisite, it seems plausible that implausibility may at least be a strong cue for noisy-channel processing (perhaps stronger than the form-based implausibility generated by *butter and bread*).

If frequency-dependent preference extremity isn't a result of noisy-channel processing, however, then how does frequency-dependent preference extremity arise? One possibility is that frequency-dependent preference extremity may be a result of accessibility effects. For example, there is evidence from the learning literature that people will use a frequent form even more frequently simply because it is more accessible [@harmonPuttingOldTools2017]. For high-frequency binomials, if one ordering is more frequent than the other ordering, it may become more accessible than the infrequent ordering. Over time, this increase my compound resulting in the more frequent ordering being used increasingly more often (i.e., frequency-dependent preference extremity). On the other hand, in the case of lower-frequency binomials, even if one ordering is more frequent, it may not occur often enough to result in a similar increase in accessibility.

In summary, the present results demonstrate that the ordering of a binomial primes the same ordering of the binomial without priming the opposite ordering. Further, this is the case regardless of whether it is the frequent ordering or the infrequent ordering that is primed. This is unexpected if noisy-channel processing results in listeners interpreting the infrequent ordering (e.g., *butter and bread*) as the frequent ordering (e.g., *bread and butter*). It is possible that either noisy-channel processing happens at a higher level, or that frequency-dependent preference extremity of binomials is not a consequence of noisy-channel processing, but rather a consequence of other mechanisms, such as a consequence of accessibility.

\clearpage

# References {.unnumbered}

::: {#refs}
:::

\newpage

# Appendix {.unnumbered}

\appendix

\renewcommand{\thesection}{\Alph{section}}

\setcounter{section}{0}

\counterwithin{figure}{section}

\counterwithin{table}{section}

# Full List of Stimuli {#sec-full-list-of-stimuli .appendix}

Our full stimuli list is included below.

::: landscape
```{r, echo = F, message = F}
#| label: tbl-appendixstimuli
#| tbl-cap: 'Full set of stimuli.'

stimuli = read_csv('../Data/key.csv') %>%
  filter(PrimeType != 'filler') %>%
  select(Binomial, RelFreq,  GenPref, PrimeType, SentenceType, Sentence, Prime) 
  
stimuli %>%
  kable(
    row.names = FALSE,
    booktabs = TRUE,
    format = "latex",
    escape = TRUE,
    longtable = TRUE
  ) %>%
  kable_styling(
    latex_options = c("striped", "hold_position"),
    font_size = 6,
    full_width = FALSE
  ) %>%
  row_spec(0, bold = TRUE)



```
:::
