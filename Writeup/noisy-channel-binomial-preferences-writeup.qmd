---
title: "How Black and White is Language Processing?"
subtitle: "An Investigation into the Noisy-channel Processing of Binomials"
editor: visual

author:
    - name: "ZACHARY NICHOLAS HOUGHTON"
      orcid: "0000-0002-0320-8881"
      degree: "Psychology"
      affiliations:
        - name: "University of California, Davis"
          department: "Department of Psychology"

degree: "Psychology"
dissertation_name: "Dissertation Name"
author_name: "ZACHARY NICHOLAS HOUGHTON"
field_of_study: "Psychology"
committee_member_1: "Dr. Fernanda Ferreira, Chair"
committee_member_2: "Dr. Emily Morgan"
committee_member_3: "Dr. John Henderson"
submission_year: "2025"
  
format:
  pdf:
    template-partials:
      - before-body.tex
      #- toc.tex
    number-sections: true
    latex-engine: xelatex 
    documentclass: scrartcl   # LaTeX document class for professional formatting
    number-depth: 3
    # Caption Formatting
    fig-cap-location: top      # Figure captions above
    tbl-cap-location: top      # Table captions above
    fig-pos: 'htbp'        # Let LaTeX decide where to place the figures
    fig-align: center       # Centering figures
    keep-tex: true             # Optional: for debugging TeX
    latex-output: houghton_thesis.tex
    # Font Settings
    fontsize: 12pt
    mainfont: "Crimson"        # Primary text font
    CJKmainfont: "Noto Serif KR"  # Font for Korean text
    link-citations: true       # Enable hyperlinked citations
    colorlinks: false          # Disable colored hyperlinks
    toc: true
    toc-depth: 3
    #toc-title: "Table of Contents"
    #lot: true                  # Enable List of Tables
    #lof: true                  # Enable List of Figures

    # Page Layout #Not supposed to use geometry for koma apparently
    geometry:
      - left=1in
      - right=1in
      - top=1in
      - bottom=1in

    include-in-header: 
      - include-in-header.tex

  docx:
    number-sections: true
    number-depth: 3
    toc-title: Table of Contents
    toc: true
    toc-depth: 3
    reference-doc: reference.docx
        
      
csl: apa.csl
bibliography: references.bib
---

```{r include = F}
library(tidyverse)
library(knitr)
library(kableExtra)
library(brms)
library(sjPlot)
library(ggpubr)

key = read_csv('../Data/key.csv')

audio_acc_70 = brm(residual_rts ~ 0 + Intercept + prime_freq * target_freq + 
            (prime_freq * target_freq | Item) + (prime_freq * target_freq | participant),
          data = audio_acc_greater_70,
          iter = 30000, 
          warmup = 15000,
          chains = 4,
          core = 4,
          thin = 4,
          prior = c(set_prior("student_t(3, 0, 30)", class = "b"),
                set_prior("student_t(3, 0, 30)", class = "sd")),
         control = list(adapt_delta = 0.99),
         file = '../Scripts/audio_accuracy_greater_70_exp3' #accuracy_greater_90
)


percent_greater_zero = data.frame(fixef(audio_acc_70, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


audio_acc_70_freq = brm(residual_rts ~ 0 + Intercept + prime_freq * target_freq + 
            (prime_freq * target_freq | Item) + (prime_freq * target_freq | participant),
          data = audio_acc_greater_70_freq,
          iter = 30000, 
          warmup = 15000,
          chains = 4,
          core = 4,
          thin = 4,
          prior = c(set_prior("student_t(3, 0, 30)", class = "b"),
                set_prior("student_t(3, 0, 30)", class = "sd")),
         control = list(adapt_delta = 0.99),
         file = '../Scripts/audio_accuracy_greater_70_freq_exp3' #accuracy_greater_90
)

percent_greater_zero_frequent = data.frame(fixef(audio_acc_70_freq, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)
```

\newpage

\doublespacing

\setlength{\parindent}{4em}

# Abstract {#sec-abstract .unnumbered}

Abstract

\newpage

\pagenumbering{arabic}

# Introduction

Humans have a great deal of flexibility when it comes to linearizing our abstract thoughts into discrete words or phrases. For example, to express uncertainty, we have a variety of options ranging from familiar expressions such as *I don't know*, to more novel expressions, such as *to me, it is uncertain*. In other words, when speaking we are faced with the decision of either accessing a holistically stored expression or generating a novel expression by combining words using knowledge of the grammar.

Traditionally, the assumption with respect to this trade off between item-specific and generative knowledge was that it is a function of a word or phrase's semantic compositionally [i.e., the degree to which the phrase's meaning could be derived from the individual words or morphemes that comprise it; @chomskyAspectsTheorySyntax1965; @pinkerFutureTense2002]. For example, according to generativist theories, regular multi-morphemic words can be composed using rules of the language. As such, a word like *cats* would be generated by accessing the holistically stored word, *cat*, and then generating *cats* by using knowledge of the grammar with respect to plural formation. Similarly, multi-word phrases, such as *I don't know* would be generated by accessing each of the individual words in the phrase and then combining them.

These theories gained a great deal of traction, partially due to concerns about memory limitations. However, more recently we have learned that the brain has a much larger memory capacity than we once thought. For example, @wangDiscoveringCapacityHuman2003 demonstrated that the human brain can store an upwards of 10^8432^ bits. Further, @mollicaHumansStoreMegabytes2019 estimated that the upper bound of memory that it would require to store linguistic knowledge is ten million bits of information, which is well within the estimated amount of storage that the human brain has.

As knowledge of the memory capacity of the brain increased, alternative accounts to holistic storage began gaining traction. These theories grew largely out of the phonetics literature where generativists' cookie-cutter approach to language quickly fell short. For example, @bybeeWordFrequencyContext2002 demonstrated that the phonetic reduction of a sound advances more greatly in high-frequency words than low-frequency words. If words are the combination of abstract phonemes, then the reduction of a phoneme should proliferate across every word that contains the phoneme. In other words, it's hard to account for the context-specificity of phoneme realizations without a storage mechanism that contains context-specific phonetic detail.

Similarly, in their seminal paper @mcmurrayGradientSensitivityWithincategory2008 demonstrated that people are sensitive to gradient changes of within-category voice onset timing (VOT). VOT is a measure of when the vocal chords begin flapping with respect to the production of a voiced or voiceless phoneme. While VOT is a continuous measure, it is used by English listeners to make a binary determine as to whether a sound is voiced or unvoiced. Following this, if phonemes are represented as abstract categories (e.g., just *p* or *b*), then VOT should only influence listener's perception if the change in VOT results in a change in the phoneme. That is, if two sounds vary in VOT but are still classified as *p*, participants should not be sensitive to the difference in VOT (if they're decomposing the word into abstract phonemes). However, @mcmurrayGradientSensitivityWithincategory2008 demonstrated that listeners *are* sensitive to within-category VOT. Specifically, they presented participants with words such as *barricade/parakeet*, where the initial sounds were either voiced or voiceless stops. They then systematically manipulated the VOT for the initial stop and measured the proportion of participants' fixations to the competitor. They found that within-category variability of VOT affected the proportion of fixations to the competitor, suggesting sensitivity to within-category variability in VOT.

These findings also sparked similar questions about the representations of multi-word phrases. For example, @bybeeEffectUsageDegrees1999 examined the phonetic reduction of *don't* in various contexts. They found that *don't* is more greatly reduced in *I don't know* than in lower-frequency phrases such as *I don't go*. In other words, the phonetic reduction of *I don't know* cannot be attributed to the phonetic reduction of any of the individual parts in isolation. This suggests that *I don't know* has a representation separate from the individual parts. @bybeeEffectUsageDegrees1999 showed similar results for other high-frequency phrases as well, such as *have to*, *want to*, etc. Similarly, @yiEumunHyeonsanggwaBindo2002 demonstrated that tensification in certain multi-word phrases in Korean is also context-specific. Specifically, in Korean certain consonants become tense when they occur after the future tense marker. @yiEumunHyeonsanggwaBindo2002 demonstrated that this tensification is more frequent in high-frequency phrases. The context-specificity of the phonetic reduction of multi-word phrases is strong evidence for the holistic storage of multi-word phrases.

In the Psycholinguistics literature, there has been a rich literature examining the multi-word holistic storage of binomials [@siyanova-chanturiaSeeingPhraseTime2011; @morganAbstractKnowledgeDirect2016; @morganFormalizingConstructionGrammar; @morganFrequencydependentRegularizationIterated2016a; @morganModelingIdiosyncraticPreferences2015; @morganProductiveKnowledgeItemspecific2024; @houghton2024frequencydependentpreferenceextremity; @houghton2023doespredictabilitydrive]. For example, @siyanova-chanturiaSeeingPhraseTime2011 demonstrated that binomials are read faster in their frequent order (e.g., *bread and butter*) than in their infrequent ordering (e.g., *butter and bread*). If binomials were represented and processed word-by-word then it is unclear how to account for this result since the individual words are identical across different orderings of the same binomial (i.e., the words in *cats and dogs* are the same as in *dogs and cats*). \

One possibility is that humans have abstract preferences for the ordering of words in phrases (e.g., a preference for short words first). @morganAbstractKnowledgeDirect2016 examined this possibility by creating a corpus of binomials and annotating them for semantic and phonological constraints known to influence binomial orderings [@benorChickenEggProbabilistic2006]. They then created a logistic model to combine these constraints into a single generative preference value that indicated the direction and magnitude of the preference.

@morganAbstractKnowledgeDirect2016 further examined whether human ordering preferences are driven by these generative preferences for binomials ranging in overall frequency (where overall frequency is the total number of times a binomial occurs in either ordering, e.g., the number of times *bread and butter* occurs plus the number of times *butter and bread* occurs). Specifically, they used a self-paced reading task and had participants read binomials in sentence contexts, and recorded their reading times. They found that for low-frequency binomials, human reading times were driven primarily by generative preferences, however for high-frequency binomials human reading times were driven primarily by relative frequency (i.e., the proportion of counts in the alphabetical ordering to the nonalphabetical ordering, e.g., the proportion of counts of *bread and butter* to counts of *butter and bread*). Their results suggest that humans compose low-frequency binomials using generative knowledge of the language, however for high-frequency binomials humans store and access a holistic representation of the entire binomial.

## Frequency-dependent Preference Extremity

Holistic storage also makes rich predictions about language change that have been born out in the literature. For example, there is evidence that ordering preferences become more extreme for high-frequency items relative to low-frequency items [@morganAbstractKnowledgeDirect2016; @liuFrequencydependentRegularizationConstituent2020; @liuFrequencyDependentRegularizationSyntactic2021]. If phrases are generated compositionally without any holistic storage, it is hard to see how high-frequency phrases would become more polarized, especially binomials since both orderings contain the same words. However, this is precisely what the literature has demonstrated. For example, @morganModelingIdiosyncraticPreferences2015 demonstrated that the ordering preferences of binomials are more extreme for high-frequency binomials relative to low-frequency binomials.

Additionally, @liuFrequencydependentRegularizationConstituent2020 demonstrated that the dative alternation (e.g., *give him the ball* vs *give the ball to him*) also shows evidence of frequency-dependent preference extremity. Specifically, they found that for high-frequency verbs, there is a stronger preference for using one dative alternation over the other than for low-frequency verbs. Similarly, @liuFrequencyDependentRegularizationSyntactic2021 examined the ordering of adjectives in adjective-adjective-noun (AAN) phrases (e.g., *dark blue sky*). They found that AAN phrases with higher overall frequency (where overall frequency is the sum of counts in either ordering) show more polarized ordering preferences.

While holistic storage is a prerequisite for frequency-dependent preference extremity, it isn't enough by itself to account for this phenomenon. That is, high-frequency binomials being stored holistically does not necessarily lead to them being used more. In addition to holistic storage, it is possible that frequency-dependent preference extremity arises as an interaction between imperfect learning and transmission across generations [@morganFrequencydependentRegularizationIterated2016a; @houghton2024frequencydependentpreferenceextremity]. Specifically, @morganFrequencydependentRegularizationIterated2016a argued that humans have a bias to regularize productions to decrease variability [@hudsonkam2005regularizingunpredictablevariation]. It is possible that this regularization bias causes high-frequency binomials to become more polarized (i.e., more regularized). Indeed, they found that a computational model that contains a frequency-independent regularization bias does result in frequency-dependent preference extremity. They demonstrated that this is because in their model, learners rely on their priors when there isn't enough data (such as in the case of lower frequency binomials), but when they have enough data they overcome their priors, resulting in more regularized/polarized productions.

Specifically @morganFrequencydependentRegularizationIterated2016a used a 2-alternative iterated learning paradigm [@realiEvolutionFrequencyDistributions2009] to simulate the evolution of binomial ordering preferences across generations of speakers. In their model, a speaker first produces N binomial expressions in either ordering in proportion to their learned preferences. For the first generation of speakers, this proportion is simply the generative preference of the binomial. The learner then "hears" these Nbinomial expressions and updates their hypothesis about the proportion that each ordering of that binomial occurs in. This data generation process alone simply results in learner's converging on the prior [@griffithsLanguageEvolutionIterated2007], which was the generative preference value for the binomial. Thus, @morganFrequencydependentRegularizationIterated2016a introduced a frequency-independent regularization bias into their model, which pressured productions to be more regular (regardless of the frequency of the binomial). Thus, if there was not strong evidence for one ordering over the other, learners' preferences was pulled towards the prior. If there was enough evidence, however, learners would learn a preference for the ordering of the binomial and that preference would become more regularized over time. This model resulted in frequency-dependent preference extremity arising across generations of learners.

However, while their results demonstrate that a frequency-independent regularization bias can account for frequency-dependent preference extremity, it's unclear what process this bias is analogous to in language learning/processing.

## Noisy-channel Processing

One possibility is that the the frequency-independent regularization bias is a consequence of noisy-channel processing.[^1]

[^1]: It is worth mentioning here that in parallel to the development of noisy-channel processing theories, other accounts making similar claims also emerged [e.g., @ferreiraGoodEnoughApproach2007]. Many of these theories accept that language processing must allow for flexibility and it's often difficult to disentangle them. While we take a noisy-channel approach in the present thesis, all of the claims we make are also compatible with good-enough processing theories as well, and we leave the task of disentangling the two theories to future work.

When processing language, we are faced with a great deal of noise in our environment. This can be literal noise in our environment, such as the sound of a loud city, or noise introduced by the communication device, such as static in a cellphone conversation. It can also be errors made by the speaker (speech errors) or by the listener (perceptual errors). Despite the abundance of noise in our environment, the language processing system appears to be quite robust to noise. One possible explanation is that people may be tracking, not simply what they are hearing, but also what they think the speaker actually intended to say [@gibsonNoisyChannelAccountCrosslinguistic2013; @levyNoisychannelModelHuman2008]. Thus in some cases where people hear something implausible, they may actually think that the speaker intended to say something else, and process it as if they did say the intended utterance.

There is a great deal of evidence that people do take noise into account. First and most obviously, when a listener misses a word due to simply not hearing it (e.g., a loud noise interrupted the utterance), it very rarely causes a complete breakdown in communication. Further, @ganongPhoneticCategorizationAuditory1980 demonstrated that people process a non-word as being a word under noisy conditions. Similarly, @feltyMisperceptionsSpokenWords found that when listeners misperceive a word, the word that they believed to have heard is a higher frequency than the word spoken. These results suggest that in noise listeners are relying on information about the language, such as what utterances are more probable, to overcome the perceptual difficulties.

Interestingly, people will sometimes even hear a grammatical sentence and interpret the meaning differently from what they have heard due to noisy-channel processing. For example @christiansonThematicRolesAssigned2001 found that when people read the sentence *While the man hunted the deer ran into the woods*, people will answer in the affirmative for the question *Did the man hunt the deer?* as well as the question *Did the deer run into the woods?*. People interpret this sentence as having been *While the man hunted the deer, it ran into the woods.* @levyNoisychannelModelHuman2008 argued that since both interpretations can arise from a single insertion, noisy-channel processing offers an explanation for this finding.

Following this, @gibsonNoisyChannelAccountCrosslinguistic2013 formalized a noisy-channel processing model using a Bayesian framework. They modeled noisy-channel processing as a process wherein the listener estimates the probability of the speaker's intended utterance ($s_i$) given what they perceived ($s_p$, @eq-gibsonnoisy) Specifically, the listener is modeled as a rational Bayesian who estimates the probability of the speaker's intended utterance given the perceived utterance as being proportional to the probability of the intended utterance in general times the probability of that perceived utterance given the intended utterance. This is formalized mathematically in @eq-gibsonnoisy [reproduced from @gibsonNoisyChannelAccountCrosslinguistic2013] where $s_i$ is the speaker's intended sentence and $s_p$ is the perceived sentence. The prior ($P(s_p|s_i)$) is the likelihood of the $s_i$ being corrupted to $s_p$.

$$
P(s_i|s_p)\propto P(s_i) P(s_p|s_i) 
$$ {#eq-gibsonnoisy}

The model in @gibsonNoisyChannelAccountCrosslinguistic2013 made several predictions. Specifically, their model predicted that comprehenders should be more likely to interpret a semantically implausible sentence (e.g., *the mother gave the candle the daughter*) as being plausible (e.g., *the mother gave the candle to the daughter*) if there is increased noise (which they accomplished by adding syntactic errors to the filler items). Their model also predicted that increasing the probability of an implausible utterance (e.g., by adding more implausible items to the fillers) should lead to an increased rate of implausible interpretations. They tested these predictions by giving participants a series of sentences, some of which were semantically implausible but had semantically plausible alternatives that participants could interpret the sentence as being. These alternatives varied in how different they were from the perceived utterances. Some of them varied from the perceived utterance by a single insertion or a single deletion, while others varied by two insertions or two deletions. By manipulating the number of semantically implausible sentences as well as the number of filler items with syntactic errors, both of the predictions that their model made were born out in experimental data that they had collected.

Given these results, @houghton2024frequencydependentpreferenceextremity extended @morganFrequencydependentRegularizationIterated2016a's model. Specifically, we used a 2-alternative iterated learning paradigm. In this paradigm, learners are modeled as having heard N tokens of a given binomial in either alphabetical or nonalphabetical order while updating a hypothesis with respect to the ordering preference for each binomial. In our model, the learner's goal was to learn the ordering preferences for each binomial. Then after learning the ordering preferences, the learner then produced N tokens to the next generation. This process then repeated iteratively.

After hearing a binomial, the learner in our model updated their beliefs in proportion to what they believed the speaker's intended ordering was, which was modeled with pseudo counts. For example, if they believed the intended utterance was A and B with 60% probability and B and A with 40% probability, then they would add 0.6 and 0.4 to the pseudo counts for A and B and B and A respectively.[^2]

[^2]: See @houghton2024frequencydependentpreferenceextremity for a more detailed explanation of our computational model.

Without a regularization bias, this model would simply result in convergence to the prior [@griffithsLanguageEvolutionIterated2007], which is equivalent to the generative preference for the binomial. Thus, our model also contained a noisy-channel processing component. After hearing a binomial, the learner in our model would interpret the opposite ordering occasionally (with probability according to @eq-gibsonnoisy). That is, if the learner hears B and A, but is confident that the intended ordering was actually A and B, they are more likely to update their beliefs as if they had heard A and B.

To help build intuition for this: suppose a learner believes there is a 60% chance that the speaker intended to say A and B, but they heard B and A. Without a noisy-channel processing component, the learner would update their belief, down-weighting the probability of A and B and up-weighting the probability of B and A. However, with noisy-channel processing, the learner may actually assume the speaker intended to say A and B (after calculating this probability according to @eq-gibsonnoisy), but had actually misspoke and said B and A. This would then result in updating their beliefs as if they had heard A and B. For high-frequency binomials, the learner encounters the binomial more and has more opportunities to interpret B and A as A and B. However, for low-frequency binomials, the learner does not encounter the binomial as many times and has fewer opportunities. In a more extreme example, if a learner believes that there is a 90% chance that the speaker intended to say A and B and a 10% chance they had intended to say B and A, then on the few trials they hear B and A, they are very likely to assume that the speaker intended to say A and B. This would result in their beliefs about the probability of the ordering being pulled closer to 100% (since in the 10% of trials they heard B and A, the learner would assume the speaker meant A and B and subsequently update their beliefs in favor of A and B) if they hear the binomial enough times to overcome the prior beliefs.

Indeed, this is precisely the result we found in @houghton2024frequencydependentpreferenceextremity. That is, that for low-frequency binomials, the learner's belief about the intended ordering was not particularly strong and was pulled towards the prior. However, for high-frequency binomials, as the learning continued iteratively across generations, frequency-dependent preference extremity arose.

Our results in @houghton2024frequencydependentpreferenceextremity demonstrated that a noisy-channel processing model in an iterative learning paradigm can predict frequency-dependent preference extremity. It also makes a crucial prediction: that learners sometimes hear *B and A*, but actually interpret it to be *B and A*. In the present study we explore this prediction.

## Present Thesis

@houghton2024frequencydependentpreferenceextremity's model predicts that learners sometimes hear one binomial ordering but interpret it to be the opposite ordering. If this is the case, then it is possible that upon hearing, e.g., *white and black*, the listener actually processes it as *black and white*. There is a great deal of evidence that activating a phrase results in decreased processing time if encountering the same phrase shortly after [e.g., @tabossi1980linguisticcontextpriming]. If this is the case, then hearing *white and black* should actually speed up the processing of *black and white* more than it speeds up the processing of *white and black*. This is the prediction that we set out to test in the present study. By using a primed self-paced reading task with a mental rotation task, we examine whether *white and black* primes *black and white* more than it primes *white and black*.

# Methods

## Procedure

In order to examine the effects of noisy-channel processing on the reading times of binomials, we used a primed self-paced reading task with a mental rotation task. Specifically, participants were first presented auditorily with a prime sentence while simultaneously completing a mental rotation task. The mental rotation task involved determining whether one was a simple rotation or a mirror image of another image. The rotation was always either 0 degrees or 45 degrees. Participants were tasked with either pressing the 'f' key or the 'j' key (counter balanced between participants) to indicate that the image was either a simple rotation or a mirror image. The idea behind the mental rotation task was that by forcing participants to multi-task they may rely more on noisy-channel processing than when they can focus solely on the prime sentences.

After listening to the prime sentence and completing the mental rotation, participants then completed a self-paced reading task. Specifically, participants were presented with a sentence word-by-word and pressed the 'space' key when they were ready to proceed to the next word. Reaction times for the time it took participants to press the 'space' key were recorded for each word. After each sentence, participants were presented with a comprehension question to test their attention. The comprehension questions were questions either about the prime sentence or the sentence they had just read.

## Stimuli

Our stimuli consisted of 30 polarized binomials.[^3] Specifically, these were binomials that occurred more than 400,000 times (out of 323,592,921,465 tokens), calculated using the Google *n*-grams corpus [@michel2011quantitativeanalysisculture]. Additionally, they all had a relative frequency of either less than -0.30 and greater than 0.30. Relative frequency indicates which ordering is more preferred (and to what magnitude). For example, a binomial that occurs equally as many times in both orders would have a relative frequency of zero (where relative frequency ranges from -0.50 to 0.50). A relative frequency value below 0 indicates that the nonalphabetical ordering occurred more than the alphabetical ordering in corpus data, and a number above zero indicates the opposite. The magnitude of the number indicates the strength, with 0.50 indicating that the binomial occurred exclusively in alphabetical ordering and -0.50 indicated the binomial occurred exclusively in nonalphabetical ordering. Thus binomials with a relative frequency below -0.3 and above 0.3 are quite polarized in their ordering.

[^3]: Our stimuli and analyses are available at the following link: <https://github.com/znhoughton/Noisy-Channel-Binomial-Preferences>. The stimuli are also included in the appendix section (@sec-full-list-of-stimuli).

For each of these binomials, we created a prime and a target sentence containing the binomial in either order. Specifically, for each binomial, three prime sentences were made: one that contained the binomial in the frequent ordering (e.g., *bread and butter*), one that contained the infrequent ordering, (*butter and bread*), and one that did not contain a binomial at all. These priming conditions are referred to as the frequent, infrequent, and unrelated primes respectively. We also made two target sentences (the sentences read during the self-paced reading task) for each binomial. The target sentences contained the binomial in either the frequent or infrequent ordering. A table demonstrating our six conditions is presented below in @tbl-conditionslist. Finally, we also included 30 filler trials, which did not contain binomials in the prime or target sentences. An example of each of our conditions is included below:

```{r echo = F}
#| label: tbl-conditionslist
#| tbl-cap: "A table of our conditions."

example_sentence = key %>% 
  filter(Item == 21) %>%
  mutate(target_word = rep(c('gentlemen and ladies', 'ladies and gentlemen'), times = 3),
         prime_word = rep(c('gentlemen and ladies', 'ladies and gentlemen', 'Unrelated'), each = 2)) %>%
  select(Condition, target_freq, prime_freq, target_word, prime_word) %>%
  mutate(target_freq = case_when(target_freq == 'not-frequent' ~ 'Infrequent',
                                 target_freq == 'frequent' ~ 'Frequent')) %>%
  mutate(prime_freq = case_when(prime_freq == 'not-frequent' ~ 'Infrequent',
                                prime_freq == 'frequent' ~ 'Frequent',
                                prime_freq == 'unrelated' ~ 'Unrelated'))

colnames(example_sentence) = c('Condition', 'Target Frequency', 'Prime Frequency', 'Target Binomial', 'Prime Binomial')
example_sentence %>%
  select(everything()) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '5em')
```

Our prime and target sentences were crossed such that each target occurred with each prime, however no participant was presented with the same binomial in more than one trial.

## Participants

228 University of California, Davis undergraduate students were given course credit to participate in the study. We also recruited an additional 220 participants through Prolific. Altogether, 448 people participated in our study.

Participants were randomly presented with one of 6 conditions. Since our design is a 3 x 2 design, 6 conditions were created so that participants did not encounter the same binomial in more than one trial.

## Analysis

We divided the sentences into a target and spillover region to be our region of analysis. This region included the 3 words in the binomial along with the 3 following words. We then excluded participants whose reading times on this region were less than 100ms or greater than 5000 ms [following @morganAbstractKnowledgeDirect2016]. We also excluded participants who had an average accuracy below 0.7 on the audio comprehension questions (the questions that asked about the auditorily presented prime). Finally, we excluded trials for which the residual reading times were outside of 2.5 standard deviations from the mean.

We then ran two Bayesian mixed-effects regression models with residual reading times as the dependent variable.[^4]

[^4]: A pre-registration of our study is available at the following link: <https://aspredicted.org/t324-swgk.pdf>.

For the first model, we were interested in whether a frequent prime affected the residual reading times. As such, we filtered the dataframe to include trials that contained either an unrelated or frequent prime. We then treatment coded our variables such that for the prime sentences, 0 indicated an unrelated prime and 1 indicated a frequent prime. For target sentences, 0 indicated an infrequent target while 1 indicated a frequent target. We then ran a model with residual reading time as the dependent variable, fixed-effects for prime, target, and their interaction, as well as maximal random-effects [following @barrRandomEffectsStructure2013].

Our second model was similar, however we were interested in how the infrequent prime affected residual reading times. As such, we filtered our dataframe to include trials that contained either the unrelated or infrequent prime. We then treatment coded our variables such that 0 indicated an unrelated prime and 1 indicated an infrequent prime.

Our model syntax was the same for both models, as mentioned previously the difference was the levels of the variables included in the data.

$$
\begin{aligned}
\text{Residual Reading Time} & \sim \text{Intercept} + \text{prime freq} * \text{target freq} \\ 
&+ (\text{prime freq} * \text{target freq} | \text{Item}) + (\text{prime freq} * \text{target freq} | \text{participant})
\end{aligned}
$$ {#eq-models}

# Results

We first examined whether a frequent prime facilitated the reading of the frequent ordering of the binomial more than the reading time of the infrequent ordering. Following @houghtonTaskdependentConsequencesDisfluency2024, in addition to reporting the estimates we also report the percentage of posterior samples greater than zero. Bayesian statistics don't force us into a binary interpretation of significance or non-significance, by reporting the percentage of posterior samples greater than zero we are able to interpret the results in a more nuanced manner.

The results are presented in @tbl-frequentresults and visualized in @fig-fullresults. Since prime and target types were treatment coded, the Intercept represents the estimated reading times for unrelated prime sentences with an infrequent target sentence. Coefficient estimates represent the distance from the Intercept. Although the credible interval crosses zero, over 93% of the posterior samples for the effect of frequent prime were greater than zero, suggesting that for not-frequent targets, the frequent prime resulted in slower reading times than the unrelated prime. Similarly, over 93% of the posterior samples for frequent target were less than zero, suggesting that for unrelated primes, the frequent target was read faster. Finally, about 90% of the samples for the interaction effect were less than zero, suggesting that the difference between the reading times in the unrelated prime condition and the reading times in the frequent prime condition were larger for infrequent targets than frequent targets. In other words, the frequent prime speeds up the reading times for the frequent ordering of the binomial more than the infrequent ordering of the binomial.

```{r, echo = F, message = F}
#| label: tbl-frequentresults
#| tbl-cap: 'Results of the statistical model for the frequent vs unrelated prime.'


m_frequent = as.data.frame(fixef(audio_acc_70_freq)) %>%
  mutate(term = c('Intercept', 'Frequent Prime', 'Frequent Target', 'Frequent Prime:Frequent Target'))

percent_greater_zero_frequent = percent_greater_zero_frequent %>%
  arrange(match(beta_coefficient, c('Intercept', 'prime_freqfrequent', 'target_freqfrequent', 'prime_freqfrequent.target_freqfrequent')))

m_frequent = m_frequent %>%
  mutate(percent_greater_zero = percent_greater_zero_frequent$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


m_frequent = m_frequent %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

m_frequent %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '14em')

```

Next we examined whether the infrequent prime speeds up the infrequent ordering of the binomial more than the frequent ordering. If readers are engaged in noisy-channel processing when listening to the prime, they may actually activate *bread and butter* when they hear *butter and bread*. This would result in the infrequent prime speeding up the *frequent* ordering of the binomial more than the infrequent ordering.

The results are presented in @tbl-infrequentresults and visualized in @fig-fullresults. Similar to the previous model, since prime and target types were treatment coded, the Intercept represents the estimated reading times for unrelated prime sentences with an infrequent target sentence. Coefficient estimates represent the distance from the Intercept. We find no meaningful main-effect for infrequent primes or frequent targets, but we do find a meaningful interaction effect. While the credible interval crosses zero, over 90% of the posterior samples were greater than zero. The results suggest that the infrequent prime speeds up reading for the infrequent target more than the frequent target.

```{r, echo = F, message = F}
#| label: tbl-infrequentresults
#| tbl-cap: 'Results of the statistical model for the infrequent vs unrelated prime.'


m_infrequent = as.data.frame(fixef(audio_acc_70)) %>%
  mutate(term = c('Intercept', 'Infrequent Prime', 'Frequent Target', 'Infrequent Prime:Frequent Target'))

percent_greater_zero = percent_greater_zero %>%
  arrange(match(beta_coefficient, c('Intercept', 'prime_freqnotMfrequent', 'target_freqfrequent', 'prime_freqnotMfrequent.target_freqfrequent')))

m_infrequent = m_infrequent %>%
  mutate(percent_greater_zero = percent_greater_zero$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


m_infrequent = m_infrequent %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

m_infrequent %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '14em')

```

```{r, echo = F, out.width = '80%', fig.align = 'center', warning = F, message = F}
#| label: fig-fullresults
#| fig-cap: "Plot of our model estimates. The x-axis represents whether the prime was unrealted, frequent, or infrequent. The y-axis corresponds to the residual reading times. Color indicates whether the target was infrequent (green) or frequent (blue). The left plot compares unrelated to frequent primes, the right plot compares unrelated to infrequent primes. The result suggest that the primed ordering is read faster regardless of whether the binomial ordering is frequent or infrequent."
#| fig-height: 5
#| fig-width: 9


p1 = plot(conditional_effects(audio_acc_70_freq), plot = F)[[3]] +
  scale_color_manual(
    values = c("not-frequent" = "#66c2a5", "frequent" = "#8da0cb"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  scale_fill_manual(
    values = c("not-frequent" = "#66c2a5", "frequent" = "#8da0cb"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  labs(
    x = 'Prime Sentence',
    y = 'Residual Reading Times',
    color = 'Target Sentence',
    fill = 'Target Sentence'
  ) +
  scale_x_discrete(
    labels = c('unrelated' = 'Unrelated', 'frequent' = 'Frequent')
  ) +
  theme_bw() +
  theme(
    axis.title = element_text(size = 16),         # Axis labels
    axis.text = element_text(size = 14),          # Axis tick labels
    legend.title = element_text(size = 14),       # Legend title
    legend.text = element_text(size = 12)         # Legend items
  )

p2 = plot(conditional_effects(audio_acc_70), plot = F)[[3]] +
  scale_color_manual(
    values = c("not-frequent" = "#66c2a5", "frequent" = "#8da0cb"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  scale_fill_manual(
    values = c("not-frequent" = "#66c2a5", "frequent" = "#8da0cb"),
    labels = c("not-frequent" = "Infrequent", "frequent" = "Frequent")
  ) +
  labs(
    x = 'Prime Sentence',
    y = 'Residual Reading Times',
    color = 'Target Sentence',
    fill = 'Target Sentence'
  ) +
  scale_x_discrete(
    labels = c('unrelated' = 'Unrelated', 'not-frequent' = 'Infrequent')
  ) +
  theme_bw() +
  theme(
    axis.title = element_text(size = 16),         # Axis labels
    axis.text = element_text(size = 14),          # Axis tick labels
    legend.title = element_text(size = 14),       # Legend title
    legend.text = element_text(size = 12)         # Legend items
  )

ggarrange(p1, p2, common.legend = T)

```

# Discussion

Our results demonstrate that both the frequent and infrequent ordering of a given binomial speeds up the reading times of the respective ordering. That is, priming the frequent ordering speeds up the reading of the frequent ordering, and priming the infrequent ordering speeds up the reading of the infrequent ordering.

Our model in @houghton2024frequencydependentpreferenceextremity predicted the opposite result, that hearing the infrequent binomial ordering might actually result in learner's accessing the frequent ordering of the binomial. One possibility is that the binomials are undergoing noisy-channel processing, but that the effects of noisy-channel processing are higher-level. For example, while the listener may be confident and potentially even interpret the sentence as containing the frequent ordering of the binomial, they still heard the acoustics of *butter and bread* which primes the reading of *butter and bread* more than *bread and butter*. It is possible that noisy-channel processing doesn't result in priming effects.

<!--# future work with a sentence recall task would be interesting instead of spr -->

On the other hand, it is also possible that binomials are not undergoing noisy-channel processing in this manner. There are a few possible explanations for why this might be. The first is that hearing polarized binomials in the opposite ordering is quite surprising. That is, hearing *butter and bread* is pretty surprising as a listener. It is possible that hearing *butter and bread* then draws attention to itself by nature of being surprising, and thus the listener is confident that they did infact hear *butter and bread*. This would explain why there is no priming of *bread and butter*.

It's also possible that the size of the units matter. Much of the literature on noisy-channel processing involves small prepositions being inserted or deleted. However in our case, many of the binomials contain many letters/sounds. It is possible that listeners are more likely to assume that the speaker forgot to say a preposition, such as *in* or *up*, than assuming that the speaker accidentally swapped two multi-syllabic words (e.g., in the case of *gentlemen and ladies* instead of *ladies and gentlemen*). Although, this seems less likely since @poppelsStructuresensitiveNoiseInference2016 found evidence that people do interpret semantically implausible sentences as being semantically plausible even if the semantically plausible interpretation requires positing a substitution.

Finally, it's possible that semantic plausibility also plays a large role in noisy-channel processing. That is, both orders of binomials are semantically plausible. It is simply the case that one is more frequent than the other. It is possible that semantic implausibility is a pre-requisite to noisy-channel processing, even if an utterance is low-frequency.

If it is the case, however, that the polarization seen in high-frequency binomials isn't a result of noisy-channel processing, however, then how does frequency-dependent preference extremity arise? One possibility is that it is a result of accessibility effects. For example, @harmonPuttingOldTools2017 demonstrated that as a form becomes more frequent, it becomes more likely to be re-used to express a novel meaning. Similarly, it is possible when speakers are producing a novel sentence, they reach for the more frequent form of the binomial simply because it is more accessible.

In summary, the present results provide evidence against a noisy-channel processing account of frequency-dependent preference extremity. We find that the infrequent ordering of a binomial does not prime the frequent ordering of a binomial, which would be expected under a noisy-channel processing account. It is possible that either noisy-channel processing happens at a higher level, or that frequency-dependent preference extremity of binomials is not a consequence of noisy-channel processing.

\clearpage

# References {.unnumbered}

::: {#refs}
:::

\newpage

# Appendix {.unnumbered}

\appendix

\renewcommand{\thesection}{\Alph{section}}

\setcounter{section}{0}

\counterwithin{figure}{section}

\counterwithin{table}{section}

# Full List of Stimuli {#sec-full-list-of-stimuli .appendix}

Our full stimuli list is included below.

::: landscape
```{r, echo = F, message = F}
#| label: tbl-appendixstimuli
#| tbl-cap: 'Full set of stimuli.'

stimuli = read_csv('../Data/key.csv') %>%
  filter(PrimeType != 'filler') %>%
  select(Binomial, RelFreq,  GenPref, PrimeType, SentenceType, Sentence, Prime) 
  
stimuli %>%
  kable(
    row.names = FALSE,
    booktabs = TRUE,
    format = "latex",
    escape = TRUE,
    longtable = TRUE
  ) %>%
  kable_styling(
    latex_options = c("striped", "hold_position"),
    font_size = 6,
    full_width = FALSE
  ) %>%
  row_spec(0, bold = TRUE)



```
:::
